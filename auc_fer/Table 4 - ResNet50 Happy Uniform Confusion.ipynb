{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from __future__ import print_function, division\n",
    "#import cv2\n",
    "import dlib\n",
    "import time\n",
    "from skimage import io\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.stats.api as sms\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import namedtuple\n",
    "from skimage.transform import rescale\n",
    "from skimage.transform import resize\n",
    "import sys\n",
    "import glob\n",
    "import PIL\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import PIL\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import cv2\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "print(os.getcwd())\n",
    "#np.random.seed(198467)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Expression</th>\n",
       "      <th>gender_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry_actor_104_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry_actor_109_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry_actor_120_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry_actor_13_0.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry_actor_132_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ImageName  Expression  gender_preds\n",
       "0  angry_actor_104_0.jpg           0             1\n",
       "1  angry_actor_109_0.jpg           0             1\n",
       "2  angry_actor_120_1.jpg           0             1\n",
       "3   angry_actor_13_0.jpg           1             0\n",
       "4  angry_actor_132_0.jpg           0             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.read_csv('ExpW_OpenFace_result_with_expression_gender_race_age.csv')\n",
    "frame = frame[['ImageName', 'Expression', 'gender_preds']]\n",
    "frame.gender_preds = frame.gender_preds.apply(lambda x: 1 if x == \"Male\" else 0)\n",
    "frame = frame[['ImageName', 'Expression', 'gender_preds']]\n",
    "frame.Expression = frame.Expression.apply(lambda x: 1 if x == 3 else 0)\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88600, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    59707\n",
       "1    28893\n",
       "Name: Expression, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.Expression.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    61108\n",
       "0    27492\n",
       "Name: gender_preds, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.gender_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['ImageName'] = frame['ImageName'].apply(lambda x: '/sdata/ExpW_cropped_by_their_coordinates/' + x) # change ImageName to full path\n",
    "frame_copy = frame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rows_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 train faces, 2000 validation faces, 2000 test faces\n",
      "\n",
      "learning rate: 0.0001\n",
      "epoch number: 3\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 0.1301,  0.2020,  0.1576,  0.1901, -0.0138,  0.1094,  0.0653,  0.0641,\n",
      "         0.2365,  0.1680,  0.0842,  0.0122, -0.0315, -0.3327,  0.1224,  0.0914,\n",
      "         0.1671,  0.0684, -0.1949,  0.2487, -0.2491, -0.0163, -0.1296,  0.0029,\n",
      "         0.1143,  0.0228, -0.0279, -0.0117, -0.0742, -0.1040,  0.2357,  0.0792,\n",
      "         0.0379, -0.0923,  0.1328, -0.1630, -0.0473, -0.1158, -0.0934,  0.0904,\n",
      "         0.0426,  0.1829,  0.0104,  0.0923, -0.0927,  0.0939, -0.4418, -0.0518,\n",
      "        -0.1590,  0.1096, -0.0011, -0.1568,  0.2121,  0.0016, -0.1645, -0.1048,\n",
      "        -0.1314,  0.0602, -0.2841, -0.0418, -0.1270, -0.2845, -0.1357, -0.1178],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 0.2288, -0.1232],\n",
      "        [ 0.1944, -0.0537],\n",
      "        [ 0.1619,  0.2789],\n",
      "        [ 0.0570, -0.2331],\n",
      "        [ 0.0311, -0.0556],\n",
      "        [ 0.1143, -0.2417],\n",
      "        [-0.1400,  0.0468],\n",
      "        [-0.2267, -0.2088],\n",
      "        [-0.4102,  0.2338],\n",
      "        [ 0.1228, -0.0713],\n",
      "        [ 0.1586,  0.0315],\n",
      "        [ 0.1070, -0.0202],\n",
      "        [ 0.0932, -0.0914],\n",
      "        [ 0.0703, -0.1112],\n",
      "        [ 0.0778, -0.0074],\n",
      "        [ 0.0026,  0.0705],\n",
      "        [-0.2001,  0.0083],\n",
      "        [ 0.0028,  0.2743],\n",
      "        [ 0.1007,  0.0135],\n",
      "        [-0.4496, -0.3041],\n",
      "        [ 0.0532, -0.3771],\n",
      "        [-0.0153,  0.0057],\n",
      "        [ 0.0666,  0.1958],\n",
      "        [ 0.0595, -0.3127],\n",
      "        [-0.1136,  0.1217],\n",
      "        [-0.0939, -0.0024],\n",
      "        [ 0.1684, -0.0646],\n",
      "        [ 0.0694,  0.1025],\n",
      "        [-0.1053, -0.2359],\n",
      "        [ 0.1633, -0.1934],\n",
      "        [-0.1291,  0.1722],\n",
      "        [ 0.0576, -0.2432],\n",
      "        [ 0.0712, -0.0810],\n",
      "        [-0.0868,  0.0056],\n",
      "        [ 0.1807, -0.4018],\n",
      "        [-0.0453, -0.0965],\n",
      "        [ 0.0625,  0.1023],\n",
      "        [ 0.0470, -0.1372],\n",
      "        [-0.1401,  0.2151],\n",
      "        [ 0.1783, -0.1936],\n",
      "        [-0.0180,  0.1451],\n",
      "        [-0.1915, -0.1428],\n",
      "        [ 0.2116, -0.0795],\n",
      "        [ 0.0536, -0.1284],\n",
      "        [-0.0426, -0.0718],\n",
      "        [ 0.1405, -0.0339],\n",
      "        [-0.1347,  0.0934],\n",
      "        [ 0.0626, -0.1014],\n",
      "        [-0.1150, -0.0287],\n",
      "        [ 0.0077,  0.0861],\n",
      "        [ 0.0872, -0.0607],\n",
      "        [-0.0065, -0.0316],\n",
      "        [ 0.0593,  0.0063],\n",
      "        [ 0.0005, -0.2026],\n",
      "        [ 0.2131,  0.2015],\n",
      "        [-0.0407,  0.0344],\n",
      "        [-0.0354, -0.2527],\n",
      "        [ 0.1672, -0.1661],\n",
      "        [-0.1399,  0.1045],\n",
      "        [ 0.1415, -0.3067],\n",
      "        [ 0.1311, -0.2930],\n",
      "        [ 0.0005, -0.2189],\n",
      "        [ 0.2745, -0.1538],\n",
      "        [ 0.1608,  0.0047]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.7192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 0: [250|250], class loss:0.37619489431381226, class accuracy: 80.69375, domain loss: 0.7032054662704468, domain accuracy: 49.89375\n",
      "Testing epoch, class loss:0.36381396604701877,  class accuracy: 84.5, mAP: 0.8710655358584989, domain loss: 0.6917151156812906, domain accuracy: 59.55\n",
      "\n",
      "Training epoch 1: [250|250], class loss:0.3545211851596832, class accuracy: 88.89375, domain loss: 0.6817831993103027, domain accuracy: 57.35625\n",
      "Testing epoch, class loss:0.3546061897650361,  class accuracy: 85.0, mAP: 0.8701326297402852, domain loss: 0.6756525244563818, domain accuracy: 59.55\n",
      "\n",
      "Training epoch 2: [250|250], class loss:0.34242045879364014, class accuracy: 88.8875, domain loss: 0.6571098566055298, domain accuracy: 59.25625\n",
      "Testing epoch, class loss:0.3546061897650361,  class accuracy: 85.0, mAP: 0.8701326297402852, domain loss: 0.6685477364808321, domain accuracy: 61.75\n",
      "\n",
      "learning rate: 1e-05\n",
      "epoch number: 6\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-3.3977, -1.1190, -1.5751, -2.4818, -0.7362, -0.8803, -4.3540, -2.7520,\n",
      "        -3.3019, -2.1918,  0.3937, -2.1933, -5.6687, -2.2889,  2.0582, -0.4384,\n",
      "        -0.5794,  0.6978, -5.0183, -1.7904,  0.1318, -5.4952,  0.0231,  0.3677,\n",
      "        -2.8927, -3.5282,  6.1519,  5.2827, -0.6875, -3.2047, -3.2568,  5.1340,\n",
      "        -2.7655, -0.2380, -0.1584, -0.8717, -3.2468, -0.7696, -0.8381, -0.6382,\n",
      "        -0.3785, -0.3857, -1.1214, -2.3609, -2.4984, -2.8853, -0.6327, -0.7602,\n",
      "         2.0794, -4.1548,  1.0160, -0.6230, -1.1752,  2.8434, -1.1444, -0.8605,\n",
      "         2.4334, -0.2030,  0.6323, -0.5005, -0.7525, -0.9194, -0.0849, -2.3358],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.4195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[-1.0917e-01, -3.6137e-01],\n",
      "        [-7.6663e-02,  1.0588e-01],\n",
      "        [ 3.1527e-01, -4.0824e-01],\n",
      "        [-2.0582e-01,  9.6583e-02],\n",
      "        [-1.4426e-01,  2.6112e-02],\n",
      "        [-3.5741e-01,  6.0716e-02],\n",
      "        [-4.8475e-01,  7.7459e-02],\n",
      "        [-1.9382e-01,  5.5196e-02],\n",
      "        [ 3.9603e-01, -6.0292e-01],\n",
      "        [ 1.5280e-01, -4.9698e-01],\n",
      "        [ 1.4832e-01, -1.4001e-01],\n",
      "        [-3.7662e-01, -1.6257e-01],\n",
      "        [-2.2405e-01, -3.0155e-01],\n",
      "        [-3.1597e-01, -2.9536e-01],\n",
      "        [ 1.5607e-01, -1.3522e-01],\n",
      "        [-1.8339e-01,  2.6191e-01],\n",
      "        [-1.9787e-01,  1.7605e-01],\n",
      "        [ 2.0518e-01, -5.0635e-02],\n",
      "        [ 2.7195e-01,  4.2385e-01],\n",
      "        [-1.9094e-01,  1.2464e-01],\n",
      "        [ 1.7119e-01, -2.1928e-01],\n",
      "        [-6.1280e-02,  1.3330e-01],\n",
      "        [-1.1317e-02,  1.9884e-02],\n",
      "        [ 1.3455e-01, -6.2672e-02],\n",
      "        [ 2.8465e-01, -1.8181e-01],\n",
      "        [ 1.1087e-01,  6.2066e-02],\n",
      "        [ 4.5018e-01, -1.9018e-01],\n",
      "        [ 6.9480e-01, -3.3551e-01],\n",
      "        [-1.4643e-01,  2.1766e-01],\n",
      "        [ 4.4219e-01,  6.9170e-02],\n",
      "        [-2.4654e-01,  9.8763e-02],\n",
      "        [ 7.3702e-01, -8.2280e-01],\n",
      "        [-1.9788e-01, -2.5816e-01],\n",
      "        [ 6.8631e-02, -2.4855e-02],\n",
      "        [-1.4202e-04,  1.7928e-02],\n",
      "        [-1.8462e-01,  5.8525e-02],\n",
      "        [ 7.8977e-02, -3.2294e-02],\n",
      "        [-1.1169e-02, -5.7141e-02],\n",
      "        [-7.7575e-02,  1.5134e-01],\n",
      "        [-6.9893e-02,  1.3787e-01],\n",
      "        [-6.1051e-02,  9.3024e-02],\n",
      "        [-5.7415e-02, -1.6923e-01],\n",
      "        [-1.6162e-01,  2.8947e-01],\n",
      "        [-3.3871e-01,  1.0594e-01],\n",
      "        [ 6.6775e-02, -4.5659e-02],\n",
      "        [-8.0036e-02, -2.2413e-01],\n",
      "        [ 8.7582e-02,  1.3386e-01],\n",
      "        [-8.6411e-03, -1.1090e-01],\n",
      "        [ 2.7316e-02, -2.3952e-01],\n",
      "        [ 3.3549e-01,  5.4033e-01],\n",
      "        [ 7.6877e-02, -1.9660e-01],\n",
      "        [ 8.0785e-02, -2.6812e-02],\n",
      "        [ 9.7880e-02, -6.8990e-03],\n",
      "        [ 3.3727e-02, -3.3186e-01],\n",
      "        [ 1.3312e-04, -1.7292e-02],\n",
      "        [-1.5475e-01, -1.4505e-02],\n",
      "        [ 3.0908e-01, -5.1675e-02],\n",
      "        [-5.1749e-02, -4.2105e-02],\n",
      "        [ 1.8876e-01, -1.8878e-01],\n",
      "        [-1.2059e-01,  5.2311e-02],\n",
      "        [-1.6348e-01,  1.1330e-02],\n",
      "        [-3.0389e-02,  1.0555e-01],\n",
      "        [-4.4972e-03, -1.4496e-01],\n",
      "        [-5.5608e-02, -8.4571e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 3: [250|250], class loss:0.398364782333374, class accuracy: 90.65625, domain loss: 0.6717121601104736, domain accuracy: 52.20625\n",
      "Testing epoch, class loss:0.3932405272498727,  class accuracy: 85.6, mAP: 0.8679369320448006, domain loss: 0.6895428951829672, domain accuracy: 50.2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 4: [250|250], class loss:0.36340218782424927, class accuracy: 93.30625, domain loss: 0.7218430638313293, domain accuracy: 55.10625\n",
      "Testing epoch, class loss:0.38103272998705506,  class accuracy: 86.15, mAP: 0.8683019766944686, domain loss: 0.6827314589172602, domain accuracy: 60.1\n",
      "\n",
      "Training epoch 5: [250|250], class loss:0.3589991331100464, class accuracy: 93.44375, domain loss: 0.7132853865623474, domain accuracy: 56.33125\n",
      "Testing epoch, class loss:0.38103272998705506,  class accuracy: 86.15, mAP: 0.8683019766944686, domain loss: 0.6815697830170393, domain accuracy: 60.6\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-4.8336,  0.3287, -3.6064, -4.6183, -2.0164, -0.2828, -5.6905, -4.3712,\n",
      "        -5.2223, -4.7854,  2.2554, -4.5005, -6.8854, -3.8829,  4.0559, -0.9471,\n",
      "        -1.9835,  2.7917, -5.7913,  1.7951, -2.3411, -5.5428,  1.4570,  4.3726,\n",
      "        -5.7664, -5.5461,  6.8044,  5.2518, -2.0765, -4.3465, -4.3430,  5.0229,\n",
      "        -3.4936,  0.3784,  0.4420, -3.7957, -5.5313,  0.0115, -3.5880, -3.1480,\n",
      "        -0.2896,  1.9935, -0.5741, -3.8583, -4.5859, -5.8375, -3.4408, -1.2381,\n",
      "         5.0865, -5.0704,  1.8679, -2.1761, -2.7555,  5.2756, -4.1805, -3.8941,\n",
      "         3.9354, -4.8203,  3.0801,  0.0833, -0.0264, -2.8522,  1.7071, -2.8579],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[-0.1857,  0.2262],\n",
      "        [ 0.0773,  0.1362],\n",
      "        [ 0.3929,  0.1529],\n",
      "        [ 0.0996,  0.1082],\n",
      "        [-0.2388,  0.0423],\n",
      "        [ 0.0347,  0.0658],\n",
      "        [ 0.0232,  0.3309],\n",
      "        [ 0.1856,  0.4124],\n",
      "        [ 0.3478,  0.3290],\n",
      "        [ 0.1134,  0.3082],\n",
      "        [ 0.1182, -0.1785],\n",
      "        [ 0.0695,  0.4702],\n",
      "        [-0.0796,  0.3090],\n",
      "        [ 0.3024,  0.2342],\n",
      "        [ 0.2228, -0.2831],\n",
      "        [-0.0824,  0.0743],\n",
      "        [ 0.1004,  0.2095],\n",
      "        [-0.0044, -0.2205],\n",
      "        [-0.2680, -0.0357],\n",
      "        [ 0.0011, -0.1365],\n",
      "        [ 0.0562,  0.0697],\n",
      "        [-0.2897,  0.2926],\n",
      "        [ 0.0721, -0.0734],\n",
      "        [ 0.5936, -0.1238],\n",
      "        [ 0.0158,  0.2659],\n",
      "        [ 0.3048,  0.3158],\n",
      "        [-0.2250, -0.5054],\n",
      "        [ 0.2857,  0.0964],\n",
      "        [-0.0585, -0.0729],\n",
      "        [ 0.3364,  0.0770],\n",
      "        [ 0.1451,  0.6870],\n",
      "        [ 0.4540, -0.2458],\n",
      "        [-0.1919,  0.0754],\n",
      "        [ 0.0427, -0.1537],\n",
      "        [ 0.1461, -0.0566],\n",
      "        [-0.0956,  0.2900],\n",
      "        [-0.3330, -0.3002],\n",
      "        [ 0.1358,  0.0044],\n",
      "        [-0.0685,  0.1022],\n",
      "        [ 0.1771,  0.1302],\n",
      "        [-0.0460,  0.0254],\n",
      "        [ 0.3157,  0.0723],\n",
      "        [ 0.0326, -0.0052],\n",
      "        [ 0.4153,  0.5849],\n",
      "        [-0.5531, -0.2178],\n",
      "        [-0.1765,  0.1875],\n",
      "        [-0.1223,  0.0373],\n",
      "        [ 0.0233,  0.0821],\n",
      "        [-0.0254, -0.2679],\n",
      "        [ 0.1853,  0.5242],\n",
      "        [ 0.2376, -0.1128],\n",
      "        [ 0.2007,  0.2413],\n",
      "        [ 0.0067,  0.2483],\n",
      "        [ 0.5452, -0.3931],\n",
      "        [-0.1427,  0.2863],\n",
      "        [-0.2799, -0.0575],\n",
      "        [ 0.5086, -0.0589],\n",
      "        [-0.0462, -0.0366],\n",
      "        [ 0.0712, -0.3098],\n",
      "        [ 0.2398,  0.2752],\n",
      "        [ 0.0180, -0.0354],\n",
      "        [-0.2660,  0.0227],\n",
      "        [-0.0928, -0.2444],\n",
      "        [ 0.3495,  0.4214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 6: [250|250], class loss:0.24552682042121887, class accuracy: 94.2125, domain loss: 0.6886793375015259, domain accuracy: 51.94375\n",
      "Testing epoch, class loss:0.4402384106069803,  class accuracy: 85.7, mAP: 0.8588564088037534, domain loss: 0.6903159879148006, domain accuracy: 60.3\n",
      "\n",
      "Training epoch 7: [250|250], class loss:0.21967439353466034, class accuracy: 96.95625, domain loss: 0.7349480390548706, domain accuracy: 55.2625\n",
      "Testing epoch, class loss:0.4396226517856121,  class accuracy: 85.85, mAP: 0.8594578374752884, domain loss: 0.684100866317749, domain accuracy: 59.2\n",
      "\n",
      "Training epoch 8: [250|250], class loss:0.2093222439289093, class accuracy: 96.98125, domain loss: 0.7054899334907532, domain accuracy: 56.6\n",
      "Testing epoch, class loss:0.4396226517856121,  class accuracy: 85.85, mAP: 0.8594578374752884, domain loss: 0.6828934103250504, domain accuracy: 59.6\n",
      "\n",
      "learning rate: 1e-06\n",
      "epoch number: 12\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-5.3468,  1.2663, -5.9405, -6.2279, -3.6647,  2.4287, -6.3495, -4.5748,\n",
      "        -6.0329, -6.2228,  2.4562, -5.1943, -7.0950, -4.4584,  4.3091, -2.6106,\n",
      "        -3.0390,  3.9824, -5.8524,  3.9456, -3.0424, -5.5661,  0.8715,  6.0989,\n",
      "        -6.4793, -6.1587,  6.2206,  4.0896, -3.2766, -5.2666, -3.6589,  5.5725,\n",
      "        -2.8360,  1.3147,  4.5942, -4.1770, -6.6525,  1.0406, -5.5493, -4.5185,\n",
      "        -2.3771,  3.5379, -2.9375, -3.8826, -5.0407, -5.6120, -5.9857, -2.5433,\n",
      "         6.8712, -4.5431,  2.1443, -3.4567, -3.7931,  5.0055, -5.7281, -4.5358,\n",
      "         3.2485, -7.6336,  4.7615, -3.8787,  1.9833, -5.1615, -0.1844, -3.6105],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.1391, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 0.4271,  0.7334],\n",
      "        [ 0.1155, -0.0109],\n",
      "        [-0.1444, -0.0162],\n",
      "        [-0.3702, -0.3280],\n",
      "        [ 0.4420,  0.4192],\n",
      "        [ 0.2093,  0.1295],\n",
      "        [ 0.3713,  0.6382],\n",
      "        [ 0.1186,  0.2289],\n",
      "        [-0.0688,  0.0103],\n",
      "        [-0.0803,  0.0304],\n",
      "        [ 0.0545,  0.0509],\n",
      "        [ 0.1702,  0.4195],\n",
      "        [ 0.5631,  0.5826],\n",
      "        [ 0.3086,  0.3846],\n",
      "        [ 0.1216,  0.1377],\n",
      "        [-0.0263,  0.0910],\n",
      "        [ 0.0290,  0.1324],\n",
      "        [ 0.2210, -0.1927],\n",
      "        [ 0.3737,  0.4027],\n",
      "        [ 0.0544, -0.1566],\n",
      "        [-0.3563, -0.3471],\n",
      "        [-0.4413,  0.2158],\n",
      "        [ 0.1900,  0.0594],\n",
      "        [ 0.1594,  0.0707],\n",
      "        [ 0.3879,  0.7042],\n",
      "        [-0.2549,  0.2758],\n",
      "        [ 0.0810, -0.7059],\n",
      "        [ 0.4305,  0.1273],\n",
      "        [ 0.3197,  0.3068],\n",
      "        [ 0.0390,  0.0675],\n",
      "        [ 0.2769,  0.5165],\n",
      "        [ 0.2680, -0.0972],\n",
      "        [ 0.2766,  0.4351],\n",
      "        [ 0.1198,  0.1007],\n",
      "        [ 0.3060,  0.0456],\n",
      "        [ 0.1529,  0.1091],\n",
      "        [ 0.3918,  0.3564],\n",
      "        [ 0.1060, -0.1201],\n",
      "        [ 0.8043,  1.0609],\n",
      "        [ 0.0372,  0.3151],\n",
      "        [ 0.1928,  0.0453],\n",
      "        [ 0.4930,  0.0837],\n",
      "        [ 0.1787,  0.1549],\n",
      "        [ 0.3234,  0.3282],\n",
      "        [ 0.0851,  0.2129],\n",
      "        [ 0.0845,  0.4562],\n",
      "        [-0.2593, -0.3988],\n",
      "        [-0.0064,  0.3144],\n",
      "        [ 0.6867, -0.2070],\n",
      "        [-0.2649, -0.2114],\n",
      "        [ 0.2167,  0.0791],\n",
      "        [-0.2360, -0.0135],\n",
      "        [-0.1397,  0.1617],\n",
      "        [ 0.3206,  0.0511],\n",
      "        [ 0.2163,  0.6823],\n",
      "        [-0.0047,  0.2780],\n",
      "        [ 0.1034, -0.3775],\n",
      "        [ 0.6414,  0.7101],\n",
      "        [ 0.2252, -0.4457],\n",
      "        [ 0.1431,  0.2732],\n",
      "        [ 0.2049,  0.0295],\n",
      "        [-0.2963, -0.3831],\n",
      "        [ 0.1972,  0.0869],\n",
      "        [ 0.3144,  0.1501]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 9: [250|250], class loss:0.20684361457824707, class accuracy: 97.175, domain loss: 0.7006375789642334, domain accuracy: 52.45\n",
      "Testing epoch, class loss:0.4357907101511955,  class accuracy: 86.15, mAP: 0.8582086260925706, domain loss: 0.6880682799965143, domain accuracy: 59.1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 10: [250|250], class loss:0.1983119249343872, class accuracy: 97.58125, domain loss: 0.7167351245880127, domain accuracy: 55.5\n",
      "Testing epoch, class loss:0.4365308010019362,  class accuracy: 86.15, mAP: 0.8582275482102039, domain loss: 0.6841459814459085, domain accuracy: 61.05\n",
      "\n",
      "Training epoch 11: [250|250], class loss:0.20091408491134644, class accuracy: 97.59375, domain loss: 0.69389808177948, domain accuracy: 57.03125\n",
      "Testing epoch, class loss:0.4365308010019362,  class accuracy: 86.15, mAP: 0.8582275482102039, domain loss: 0.6837697010487318, domain accuracy: 60.65\n",
      "\n",
      "Training epoch 12: [250|250], class loss:0.17425507307052612, class accuracy: 97.6625, domain loss: 0.687990128993988, domain accuracy: 52.575\n",
      "Testing epoch, class loss:0.44140707328915596,  class accuracy: 86.1, mAP: 0.8556180017080395, domain loss: 0.6884503811597824, domain accuracy: 61.9\n",
      "\n",
      "Training epoch 13: [250|250], class loss:0.16574952006340027, class accuracy: 98.025, domain loss: 0.6971829533576965, domain accuracy: 55.79375\n",
      "Testing epoch, class loss:0.44192728819325566,  class accuracy: 86.1, mAP: 0.8556276877237424, domain loss: 0.6844833306968212, domain accuracy: 60.55\n",
      "\n",
      "Training epoch 14: [250|250], class loss:0.1617826223373413, class accuracy: 98.0, domain loss: 0.7173395752906799, domain accuracy: 56.86875\n",
      "Testing epoch, class loss:0.44192728819325566,  class accuracy: 86.1, mAP: 0.8556276877237424, domain loss: 0.6841645147651434, domain accuracy: 60.05\n",
      "\n",
      "Training epoch 15: [250|250], class loss:0.15285536646842957, class accuracy: 98.0375, domain loss: 0.7141039967536926, domain accuracy: 52.2125\n",
      "Testing epoch, class loss:0.4492020020261407,  class accuracy: 85.85, mAP: 0.8526855575495298, domain loss: 0.6889137476682663, domain accuracy: 61.25\n",
      "\n",
      "Training epoch 16: [250|250], class loss:0.14188604056835175, class accuracy: 98.4125, domain loss: 0.7068877816200256, domain accuracy: 56.26875\n",
      "Testing epoch, class loss:0.44961065892130136,  class accuracy: 85.85, mAP: 0.8527524474208649, domain loss: 0.6848841123282909, domain accuracy: 60.2\n",
      "\n",
      "Training epoch 17: [250|250], class loss:0.14471058547496796, class accuracy: 98.3875, domain loss: 0.7207269668579102, domain accuracy: 57.4875\n",
      "Testing epoch, class loss:0.44961065892130136,  class accuracy: 85.85, mAP: 0.8527524474208649, domain loss: 0.6844947542995214, domain accuracy: 59.85\n",
      "\n",
      "Training epoch 18: [250|250], class loss:0.12062239646911621, class accuracy: 98.475, domain loss: 0.6787870526313782, domain accuracy: 52.3625\n",
      "Testing epoch, class loss:0.4584500277414918,  class accuracy: 85.6, mAP: 0.8496871975581438, domain loss: 0.6886905897408724, domain accuracy: 55.95\n",
      "\n",
      "Training epoch 19: [250|250], class loss:0.13108506798744202, class accuracy: 98.7375, domain loss: 0.6911202669143677, domain accuracy: 56.025\n",
      "Testing epoch, class loss:0.45873287320137024,  class accuracy: 85.65, mAP: 0.8497246714942359, domain loss: 0.6848071850836277, domain accuracy: 60.2\n",
      "\n",
      "Training epoch 20: [250|250], class loss:0.12414786219596863, class accuracy: 98.74375, domain loss: 0.6970552206039429, domain accuracy: 56.48125\n",
      "Testing epoch, class loss:0.45873287320137024,  class accuracy: 85.65, mAP: 0.8497246714942359, domain loss: 0.6844513770192862, domain accuracy: 60.05\n",
      "Finish training epoch 21, dev class loss: 0.45873287320137024, dev doamin loss: 0.6844513770192862, dev mAP: 0.8497246714942359,domain_accuracy: 60.05, time used: 0:51:30.492146\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "   model_random_state  test_accuracy  test_gender_accuracy  \\\n",
      "0                   1          0.845                0.5985   \n",
      "\n",
      "   test_male_true_proportion  test_female_true_proportion  \\\n",
      "0                   0.302895                     0.398162   \n",
      "\n",
      "   test_male_predicted_proportion  test_female_predicted_proportion  \\\n",
      "0                        0.290275                          0.381317   \n",
      "\n",
      "   test_male_average_score  test_female_average_score  \\\n",
      "0                 0.297638                   0.378439   \n",
      "\n",
      "   balanced_chicago_accuracy  ...  \\\n",
      "0                   0.960924  ...   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion  \\\n",
      "0                                      0.342037   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion  selected_2_chicago_bias  \\\n",
      "0                                        0.383812                 0.041775   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion_raw  \\\n",
      "0                                          0.261097   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion_raw  \\\n",
      "0                                           0.313316    \n",
      "\n",
      "   selected_2_chicago_bias_raw  selected_2_chicago_male_score  \\\n",
      "0                     0.052219                       0.253493   \n",
      "\n",
      "   selected_2_chicago_female_score  \\\n",
      "0                         0.297996   \n",
      "\n",
      "   selected_2_chicago_male_score_neutral_faces  \\\n",
      "0                                     0.002771   \n",
      "\n",
      "   selected_2_chicago_female_score_neutral_faces  \n",
      "0                                       0.011685  \n",
      "\n",
      "[1 rows x 54 columns]\n",
      "16000 train faces, 2000 validation faces, 2000 test faces\n",
      "\n",
      "learning rate: 0.0001\n",
      "epoch number: 3\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-2.7628e-01, -3.6559e-01,  2.2553e-01, -1.6221e-01, -4.3718e-02,\n",
      "        -1.9205e-01,  4.5698e-02,  3.1262e-02, -8.4768e-02,  1.2743e-04,\n",
      "        -1.4262e-01, -2.8740e-01, -1.6234e-01, -2.2548e-01, -2.6030e-03,\n",
      "         6.1643e-02, -7.0939e-02,  9.3062e-02, -1.3453e-01,  2.0473e-01,\n",
      "        -3.8089e-01, -7.5096e-02, -7.5247e-04,  7.9603e-02,  4.5091e-02,\n",
      "        -5.4334e-02, -1.4618e-01,  5.8729e-02,  3.1379e-02, -1.2907e-01,\n",
      "        -1.6559e-01, -2.6766e-01,  7.2944e-03, -1.9965e-01, -4.9321e-02,\n",
      "         1.1197e-01, -5.6806e-02, -2.1675e-01, -2.1981e-01,  5.0469e-03,\n",
      "        -6.2555e-02, -1.3404e-01, -7.8929e-02, -5.6798e-02, -1.5473e-01,\n",
      "        -1.1775e-01, -1.2361e-01, -1.3477e-01, -5.8710e-02, -2.0939e-01,\n",
      "        -8.8774e-02, -1.4121e-01, -9.2083e-03, -2.5061e-01, -4.7748e-02,\n",
      "         6.3860e-02, -9.5133e-02,  2.1851e-01, -1.8488e-01,  1.5949e-01,\n",
      "        -1.7128e-01, -3.2372e-01, -5.6666e-02, -1.1682e-02], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.6767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 0.0354, -0.0377],\n",
      "        [ 0.0199, -0.2018],\n",
      "        [ 0.1846,  0.1068],\n",
      "        [ 0.1437, -0.0245],\n",
      "        [-0.0754, -0.1507],\n",
      "        [ 0.0773,  0.0621],\n",
      "        [-0.1362,  0.1283],\n",
      "        [-0.0280, -0.2219],\n",
      "        [-0.0483, -0.0733],\n",
      "        [-0.0758, -0.0555],\n",
      "        [-0.0255, -0.0803],\n",
      "        [ 0.0455, -0.2962],\n",
      "        [-0.0526, -0.3559],\n",
      "        [-0.1436,  0.0355],\n",
      "        [-0.1807,  0.0409],\n",
      "        [ 0.1800, -0.2604],\n",
      "        [-0.1340,  0.0577],\n",
      "        [ 0.0491,  0.1483],\n",
      "        [ 0.0418, -0.0966],\n",
      "        [ 0.0665, -0.3184],\n",
      "        [ 0.2154, -0.0182],\n",
      "        [-0.3693, -0.0111],\n",
      "        [-0.0193, -0.2650],\n",
      "        [ 0.0560, -0.0995],\n",
      "        [-0.1089, -0.0413],\n",
      "        [ 0.1440,  0.1464],\n",
      "        [ 0.0287, -0.3731],\n",
      "        [-0.1573, -0.0971],\n",
      "        [-0.0155, -0.2120],\n",
      "        [ 0.0554, -0.0700],\n",
      "        [ 0.1075,  0.2257],\n",
      "        [-0.0587, -0.2472],\n",
      "        [-0.0272, -0.1252],\n",
      "        [ 0.0664,  0.0199],\n",
      "        [-0.2983,  0.1485],\n",
      "        [ 0.2327,  0.2162],\n",
      "        [-0.0538,  0.1817],\n",
      "        [-0.3011,  0.1085],\n",
      "        [ 0.0283,  0.2797],\n",
      "        [-0.1019, -0.0800],\n",
      "        [ 0.1303, -0.0854],\n",
      "        [ 0.0169,  0.4678],\n",
      "        [-0.2249, -0.3795],\n",
      "        [-0.3035,  0.0663],\n",
      "        [ 0.0311, -0.1163],\n",
      "        [ 0.1918, -0.3560],\n",
      "        [-0.4461, -0.0764],\n",
      "        [-0.0469,  0.0801],\n",
      "        [ 0.1567,  0.0649],\n",
      "        [-0.1573, -0.1171],\n",
      "        [ 0.0442, -0.1365],\n",
      "        [ 0.0504, -0.0034],\n",
      "        [-0.1310, -0.1858],\n",
      "        [-0.0525,  0.1117],\n",
      "        [-0.1480, -0.0235],\n",
      "        [ 0.0483, -0.1333],\n",
      "        [ 0.2692, -0.2430],\n",
      "        [ 0.0680,  0.0612],\n",
      "        [-0.1629,  0.2163],\n",
      "        [-0.1265, -0.0904],\n",
      "        [ 0.0973,  0.0838],\n",
      "        [-0.1801,  0.0787],\n",
      "        [-0.0963,  0.1187],\n",
      "        [-0.0020, -0.1255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0: [250|250], class loss:0.3580441474914551, class accuracy: 81.275, domain loss: 0.6952103972434998, domain accuracy: 50.25\n",
      "Testing epoch, class loss:0.32580867735669017,  class accuracy: 86.45, mAP: 0.8818379792000343, domain loss: 0.6930690445005894, domain accuracy: 40.4\n",
      "\n",
      "Training epoch 1: [250|250], class loss:0.3249955475330353, class accuracy: 88.85625, domain loss: 0.6754697561264038, domain accuracy: 56.3875\n",
      "Testing epoch, class loss:0.32648892886936665,  class accuracy: 86.25, mAP: 0.8812850280124198, domain loss: 0.6781913638114929, domain accuracy: 56.1\n",
      "\n",
      "Training epoch 2: [250|250], class loss:0.33062225580215454, class accuracy: 88.8875, domain loss: 0.7150474190711975, domain accuracy: 56.825\n",
      "Testing epoch, class loss:0.32648892886936665,  class accuracy: 86.25, mAP: 0.8812850280124198, domain loss: 0.6745137479156256, domain accuracy: 61.1\n",
      "\n",
      "learning rate: 1e-05\n",
      "epoch number: 6\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 3.5302, -3.5707, -0.8580, -0.1885, -3.1307, -3.1159, -1.7753, -0.4206,\n",
      "        -0.5435, -1.7930, -2.9324, -2.0734, -2.5129, -0.2371, -3.2261,  0.8121,\n",
      "        -1.5461,  5.6658, -2.8860, -1.5360, -0.9289,  4.4824, -4.0592, -1.8344,\n",
      "        -1.1320, -2.8781,  1.0801,  0.1448, -1.7666, -4.3464, -0.1482, -2.3035,\n",
      "         1.1706, -2.5988,  3.4973, -0.8567,  2.6978, -2.6905, -3.2949, -1.2913,\n",
      "        -0.5444, -2.6314, -0.8552, -0.9102, -2.0735, -0.9463, -1.1968,  6.3011,\n",
      "        -0.9236, -1.5579, -2.2544, -2.4086, -2.2405, -0.8488, -1.1309, -3.0233,\n",
      "         2.3056, -0.9845, -2.0759, -0.9250, -0.7553, -1.1738,  2.4295, -0.6966],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.4169, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[-0.5573, -0.5024],\n",
      "        [-0.8586, -0.3711],\n",
      "        [-0.1351, -0.2899],\n",
      "        [-0.0241, -0.2646],\n",
      "        [-0.4803, -0.0119],\n",
      "        [-0.5558, -0.2837],\n",
      "        [-0.2813, -0.2239],\n",
      "        [-0.1428, -0.0860],\n",
      "        [-0.1367, -0.1269],\n",
      "        [-0.4458, -0.1398],\n",
      "        [-0.4688, -0.4922],\n",
      "        [-0.5116, -0.3914],\n",
      "        [-0.3224, -0.4756],\n",
      "        [-0.2522, -0.2154],\n",
      "        [-0.8657, -0.3946],\n",
      "        [-0.0340, -0.0912],\n",
      "        [-0.3873, -0.5256],\n",
      "        [ 0.4259, -0.3645],\n",
      "        [-0.8067, -0.2955],\n",
      "        [ 0.0845, -0.3248],\n",
      "        [-0.0174, -0.2654],\n",
      "        [-0.0254, -0.5286],\n",
      "        [-0.4934, -0.6410],\n",
      "        [-0.5124, -0.3030],\n",
      "        [-0.0830, -0.6053],\n",
      "        [-0.4744, -0.0336],\n",
      "        [-0.2694, -0.1342],\n",
      "        [-0.2410, -0.1146],\n",
      "        [-0.1792, -0.0552],\n",
      "        [-0.8265, -0.8525],\n",
      "        [-0.3230, -0.0584],\n",
      "        [-0.6084, -0.4197],\n",
      "        [-0.1249, -0.2643],\n",
      "        [-0.3719, -0.5881],\n",
      "        [-0.1684, -0.3209],\n",
      "        [-0.3461, -0.1299],\n",
      "        [ 0.0939, -0.6803],\n",
      "        [-0.5555, -0.3449],\n",
      "        [-0.2997,  0.0603],\n",
      "        [-0.3213, -0.5332],\n",
      "        [-0.2705, -0.1647],\n",
      "        [-0.1309, -0.2206],\n",
      "        [-0.4468, -0.2538],\n",
      "        [-0.0912, -0.4167],\n",
      "        [-0.3563, -0.4916],\n",
      "        [-0.1538, -0.2449],\n",
      "        [-0.3814, -0.4495],\n",
      "        [ 0.1496, -0.5500],\n",
      "        [-0.2394, -0.1873],\n",
      "        [-0.3281, -0.2383],\n",
      "        [-0.6595, -0.4086],\n",
      "        [-0.3045, -0.6394],\n",
      "        [-0.2990, -0.0161],\n",
      "        [-0.3273, -0.1583],\n",
      "        [-0.2001, -0.3312],\n",
      "        [-0.6086, -0.4567],\n",
      "        [-0.1959, -0.2302],\n",
      "        [-0.3085, -0.2702],\n",
      "        [-0.4392, -0.4931],\n",
      "        [-0.1052, -0.4648],\n",
      "        [-0.0194, -0.4425],\n",
      "        [-0.1101, -0.1190],\n",
      "        [-0.0361, -0.4642],\n",
      "        [-0.3109, -0.2890]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 3: [250|250], class loss:0.21434229612350464, class accuracy: 90.95625, domain loss: 0.6906947493553162, domain accuracy: 50.8875\n",
      "Testing epoch, class loss:0.37162304134108126,  class accuracy: 86.3, mAP: 0.880936454414934, domain loss: 0.6906849555671215, domain accuracy: 58.45\n",
      "\n",
      "Training epoch 4: [250|250], class loss:0.1954527646303177, class accuracy: 93.875, domain loss: 0.7301985025405884, domain accuracy: 56.41875\n",
      "Testing epoch, class loss:0.36921630310826004,  class accuracy: 86.45, mAP: 0.8807841863190539, domain loss: 0.6809746064245701, domain accuracy: 61.5\n",
      "\n",
      "Training epoch 5: [250|250], class loss:0.19339987635612488, class accuracy: 93.8875, domain loss: 0.6965264678001404, domain accuracy: 56.725\n",
      "Testing epoch, class loss:0.36921630310826004,  class accuracy: 86.45, mAP: 0.8807841863190539, domain loss: 0.6795551180839539, domain accuracy: 60.9\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 4.0651, -4.8401, -0.4475,  2.9981, -3.8162, -4.8991, -3.7539, -1.0455,\n",
      "         0.1641, -4.7444, -4.5275, -4.2218, -3.4436, -1.3122, -5.0354,  2.4804,\n",
      "        -2.9230,  6.7971, -4.3385, -3.8697,  1.1095,  6.7220, -5.0029, -3.7022,\n",
      "        -2.7232, -4.1734,  2.0765,  1.3547, -3.8635, -5.9536,  0.1893, -5.5967,\n",
      "         0.9170, -2.8827,  5.2017, -2.9968,  4.8632, -1.8837, -3.6806, -3.4713,\n",
      "         1.7042, -3.6581, -3.0587, -2.2993, -3.9677,  0.7827, -1.1346,  4.9536,\n",
      "        -2.4195, -3.0358, -3.1936, -4.5391, -3.9097, -1.5841, -1.5414, -4.0251,\n",
      "         2.8902, -2.1910, -5.6594,  0.1356, -0.3946, -2.5499,  4.6984, -3.7684],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.2869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[-0.0930, -0.4967],\n",
      "        [-0.3493,  0.0371],\n",
      "        [-0.3295, -0.2539],\n",
      "        [ 0.0696, -0.3175],\n",
      "        [-0.7188, -0.5093],\n",
      "        [-0.7932, -0.0433],\n",
      "        [-0.7088, -0.5100],\n",
      "        [-0.2923, -0.1445],\n",
      "        [-0.1975, -0.3275],\n",
      "        [-0.2648, -0.0510],\n",
      "        [-0.4354, -0.4684],\n",
      "        [-0.4948, -0.6750],\n",
      "        [-0.4953, -0.2683],\n",
      "        [-0.2919, -0.3542],\n",
      "        [-0.7714, -0.4872],\n",
      "        [-0.0445, -0.2890],\n",
      "        [-0.4362, -0.2853],\n",
      "        [ 0.1247, -0.7361],\n",
      "        [-0.2333,  0.1786],\n",
      "        [ 0.0221, -0.1714],\n",
      "        [-0.1761, -0.1760],\n",
      "        [-0.0696, -1.1176],\n",
      "        [-0.3801,  0.0066],\n",
      "        [-0.6483, -0.4383],\n",
      "        [-0.2099, -0.3091],\n",
      "        [-0.6570, -0.1571],\n",
      "        [ 0.0176, -0.2473],\n",
      "        [-0.2126, -0.3181],\n",
      "        [-0.2017, -0.0290],\n",
      "        [-0.0344,  0.0272],\n",
      "        [-0.1585, -0.0471],\n",
      "        [-0.8789, -0.3360],\n",
      "        [-0.1056, -0.2685],\n",
      "        [-0.1435, -0.0452],\n",
      "        [-0.1339, -0.3159],\n",
      "        [-0.5845, -0.1079],\n",
      "        [-0.1790, -0.1604],\n",
      "        [-0.1140, -0.2040],\n",
      "        [-0.8062, -0.2271],\n",
      "        [-0.3574, -0.0338],\n",
      "        [-0.0167, -0.1277],\n",
      "        [-0.4624,  0.1276],\n",
      "        [-0.4647, -0.2741],\n",
      "        [-0.2198, -0.1966],\n",
      "        [-0.4593, -0.6814],\n",
      "        [-0.0868, -0.2997],\n",
      "        [-0.2626, -0.1949],\n",
      "        [-0.4865, -0.8388],\n",
      "        [-0.2174, -0.0883],\n",
      "        [-0.1109, -0.0911],\n",
      "        [-0.5633, -0.1394],\n",
      "        [-0.8588, -0.5187],\n",
      "        [-0.3341,  0.0120],\n",
      "        [-0.4152, -0.3885],\n",
      "        [-0.1467, -0.2559],\n",
      "        [-0.6658, -0.0980],\n",
      "        [-0.2017, -0.4926],\n",
      "        [-0.1608, -0.2128],\n",
      "        [-0.6580, -0.4901],\n",
      "        [-0.1146, -0.1485],\n",
      "        [-0.1249, -0.2250],\n",
      "        [-0.4820, -0.2575],\n",
      "        [ 0.5719, -0.6289],\n",
      "        [-0.7510, -0.3703]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6588, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 6: [250|250], class loss:0.12661783397197723, class accuracy: 94.275, domain loss: 0.7055932879447937, domain accuracy: 50.96875\n",
      "Testing epoch, class loss:0.4495045836083591,  class accuracy: 86.45, mAP: 0.8663786060253399, domain loss: 0.6897610686719418, domain accuracy: 53.25\n",
      "\n",
      "Training epoch 7: [250|250], class loss:0.10431375354528427, class accuracy: 97.25, domain loss: 0.6788730025291443, domain accuracy: 55.71875\n",
      "Testing epoch, class loss:0.4480992378666997,  class accuracy: 86.35, mAP: 0.866087372927852, domain loss: 0.6807694807648659, domain accuracy: 61.3\n",
      "\n",
      "Training epoch 8: [250|250], class loss:0.10846435278654099, class accuracy: 97.25, domain loss: 0.6770976781845093, domain accuracy: 56.54375\n",
      "Testing epoch, class loss:0.4480992378666997,  class accuracy: 86.35, mAP: 0.866087372927852, domain loss: 0.6790521275252104, domain accuracy: 61.55\n",
      "\n",
      "learning rate: 1e-06\n",
      "epoch number: 12\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 3.8719, -4.9440,  1.9689,  4.4515, -4.6855, -5.0787, -4.5945, -1.1906,\n",
      "        -5.0142, -6.3664, -5.9518, -4.2385, -3.0587, -0.9850, -4.7765,  4.1444,\n",
      "        -3.2429,  6.3114, -4.7608, -6.6630,  3.7274,  6.6706, -4.5951, -5.3563,\n",
      "        -3.4770, -4.0803,  1.8262,  1.7169, -5.8023, -6.0555, -1.3195, -5.9020,\n",
      "        -3.7199, -0.7385,  5.8635, -3.6895,  4.6674, -0.5009, -3.5560, -4.5049,\n",
      "         2.8910, -4.6187, -5.6707, -3.9159, -4.3536, -4.7221,  1.6333,  4.7716,\n",
      "        -2.9674, -3.8620, -4.3683, -5.2093, -4.5083, -3.4287, -3.2147, -4.1758,\n",
      "         0.7348, -2.8168, -6.4842,  5.1206, -2.4216, -1.3195,  4.9809, -4.4990],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.0904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[-0.3854, -0.3880],\n",
      "        [-0.7038, -0.4223],\n",
      "        [ 0.0908, -0.0420],\n",
      "        [ 0.1354, -0.6935],\n",
      "        [-0.5524, -0.2276],\n",
      "        [-0.2983, -0.0585],\n",
      "        [-0.1497,  0.0059],\n",
      "        [-0.4058, -0.2227],\n",
      "        [-0.3291,  0.0567],\n",
      "        [-0.9293, -0.1783],\n",
      "        [-0.8680, -0.8065],\n",
      "        [-0.4226, -0.2658],\n",
      "        [-0.4777, -0.4182],\n",
      "        [-0.2774, -0.2648],\n",
      "        [-0.5900, -0.5275],\n",
      "        [-0.1156, -0.6287],\n",
      "        [-0.3083, -0.2777],\n",
      "        [-0.2754, -0.7226],\n",
      "        [-0.2521, -0.1360],\n",
      "        [-0.4441, -0.5193],\n",
      "        [-0.0462, -0.4170],\n",
      "        [-0.1163, -0.8308],\n",
      "        [-0.7851, -0.5107],\n",
      "        [-0.1653, -0.0393],\n",
      "        [-0.0863, -0.0378],\n",
      "        [-0.1151, -0.0464],\n",
      "        [-0.1540, -0.1852],\n",
      "        [-0.0787, -0.3856],\n",
      "        [-0.9623, -0.7201],\n",
      "        [-0.6310, -0.6467],\n",
      "        [-0.3231, -0.2183],\n",
      "        [-0.2279,  0.2234],\n",
      "        [-0.2412, -0.3979],\n",
      "        [-0.2458, -0.1891],\n",
      "        [ 0.0428, -0.7555],\n",
      "        [ 0.0622,  0.1309],\n",
      "        [-0.4790, -0.6678],\n",
      "        [-0.0081, -0.1611],\n",
      "        [-0.4655, -0.2744],\n",
      "        [-0.7417, -0.5304],\n",
      "        [ 0.0486, -0.2251],\n",
      "        [-0.8353, -0.7495],\n",
      "        [-0.0766,  0.0616],\n",
      "        [-0.2860, -0.2863],\n",
      "        [-0.3027, -0.4206],\n",
      "        [-0.1343, -0.2310],\n",
      "        [-0.0748, -0.3389],\n",
      "        [-0.5025, -0.6384],\n",
      "        [-0.3635, -0.1018],\n",
      "        [-0.3623, -0.0594],\n",
      "        [-0.2198, -0.0930],\n",
      "        [-0.4923, -0.5500],\n",
      "        [-0.3417, -0.3766],\n",
      "        [-0.3584, -0.1867],\n",
      "        [-0.3282, -0.3015],\n",
      "        [-0.7036, -0.5965],\n",
      "        [-0.0616, -0.2677],\n",
      "        [-0.3012, -0.2908],\n",
      "        [-0.9682, -0.4422],\n",
      "        [-0.2807, -0.3290],\n",
      "        [-0.3099, -0.0866],\n",
      "        [-0.2752, -0.2818],\n",
      "        [-0.2316, -0.2366],\n",
      "        [-0.0634, -0.0323]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 9: [250|250], class loss:0.09297940880060196, class accuracy: 97.43125, domain loss: 0.6851037740707397, domain accuracy: 52.00625\n",
      "Testing epoch, class loss:0.4556871806271374,  class accuracy: 86.4, mAP: 0.8619318436859104, domain loss: 0.6880425158888102, domain accuracy: 61.4\n",
      "\n",
      "Training epoch 10: [250|250], class loss:0.09398119151592255, class accuracy: 97.7875, domain loss: 0.6768142580986023, domain accuracy: 57.2\n",
      "Testing epoch, class loss:0.45607478474266827,  class accuracy: 86.35, mAP: 0.8619487304632969, domain loss: 0.6807053759694099, domain accuracy: 62.75\n",
      "\n",
      "Training epoch 11: [250|250], class loss:0.09965209662914276, class accuracy: 97.7375, domain loss: 0.6733266115188599, domain accuracy: 57.29375\n",
      "Testing epoch, class loss:0.45607478474266827,  class accuracy: 86.35, mAP: 0.8619487304632969, domain loss: 0.6803101133555174, domain accuracy: 62.45\n",
      "\n",
      "Training epoch 12: [250|250], class loss:0.08881501853466034, class accuracy: 97.86875, domain loss: 0.6813337802886963, domain accuracy: 52.3625\n",
      "Testing epoch, class loss:0.4645602903328836,  class accuracy: 86.25, mAP: 0.8576777413549799, domain loss: 0.6884770039469004, domain accuracy: 56.55\n",
      "\n",
      "Training epoch 13: [250|250], class loss:0.10070637613534927, class accuracy: 98.19375, domain loss: 0.6968095302581787, domain accuracy: 56.14375\n",
      "Testing epoch, class loss:0.4647943419404328,  class accuracy: 86.25, mAP: 0.8576140164717829, domain loss: 0.6815195064991713, domain accuracy: 62.85\n",
      "\n",
      "Training epoch 14: [250|250], class loss:0.09495812654495239, class accuracy: 98.2125, domain loss: 0.690836489200592, domain accuracy: 57.91875\n",
      "Testing epoch, class loss:0.4647943419404328,  class accuracy: 86.25, mAP: 0.8576140164717829, domain loss: 0.6810670718550682, domain accuracy: 62.3\n",
      "\n",
      "Training epoch 15: [250|250], class loss:0.08721470087766647, class accuracy: 98.31875, domain loss: 0.7147395610809326, domain accuracy: 52.075\n",
      "Testing epoch, class loss:0.47397295967675745,  class accuracy: 86.35, mAP: 0.8539303600201457, domain loss: 0.6884002517908812, domain accuracy: 60.75\n",
      "\n",
      "Training epoch 16: [250|250], class loss:0.08243286609649658, class accuracy: 98.55625, domain loss: 0.67228764295578, domain accuracy: 56.8625\n",
      "Testing epoch, class loss:0.4742818442173302,  class accuracy: 86.3, mAP: 0.8539269113567938, domain loss: 0.6818955149501562, domain accuracy: 62.6\n",
      "\n",
      "Training epoch 17: [250|250], class loss:0.088189035654068, class accuracy: 98.58125, domain loss: 0.6727282404899597, domain accuracy: 57.84375\n",
      "Testing epoch, class loss:0.4742818442173302,  class accuracy: 86.3, mAP: 0.8539269113567938, domain loss: 0.6815360747277737, domain accuracy: 62.2\n",
      "\n",
      "Training epoch 18: [250|250], class loss:0.0834367573261261, class accuracy: 98.6, domain loss: 0.6860084533691406, domain accuracy: 52.48125\n",
      "Testing epoch, class loss:0.4832412551622838,  class accuracy: 86.05, mAP: 0.8510830074006542, domain loss: 0.6890490148216486, domain accuracy: 53.55\n",
      "\n",
      "Training epoch 19: [250|250], class loss:0.07384569197893143, class accuracy: 98.79375, domain loss: 0.6851558089256287, domain accuracy: 56.65\n",
      "Testing epoch, class loss:0.4835346410982311,  class accuracy: 86.05, mAP: 0.8510984817504205, domain loss: 0.6821476351469755, domain accuracy: 62.45\n",
      "\n",
      "Training epoch 20: [250|250], class loss:0.0762774795293808, class accuracy: 98.76875, domain loss: 0.6968731880187988, domain accuracy: 57.59375\n",
      "Testing epoch, class loss:0.4835346410982311,  class accuracy: 86.05, mAP: 0.8510984817504205, domain loss: 0.6817197725176811, domain accuracy: 61.9\n",
      "Finish training epoch 21, dev class loss: 0.4835346410982311, dev doamin loss: 0.6817197725176811, dev mAP: 0.8510984817504205,domain_accuracy: 61.9, time used: 0:53:18.516607\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "   model_random_state  test_accuracy  test_gender_accuracy  \\\n",
      "0                   1         0.8450                0.5985   \n",
      "1                   2         0.8565                0.6160   \n",
      "\n",
      "   test_male_true_proportion  test_female_true_proportion  \\\n",
      "0                   0.302895                     0.398162   \n",
      "1                   0.319911                     0.409712   \n",
      "\n",
      "   test_male_predicted_proportion  test_female_predicted_proportion  \\\n",
      "0                        0.290275                          0.381317   \n",
      "1                        0.275913                          0.379363   \n",
      "\n",
      "   test_male_average_score  test_female_average_score  \\\n",
      "0                 0.297638                   0.378439   \n",
      "1                 0.280973                   0.386162   \n",
      "\n",
      "   balanced_chicago_accuracy  ...  \\\n",
      "0                   0.960924  ...   \n",
      "1                   0.914742  ...   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion  \\\n",
      "0                                      0.342037   \n",
      "1                                      0.344648   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion  selected_2_chicago_bias  \\\n",
      "0                                        0.383812                 0.041775   \n",
      "1                                        0.381201                 0.036554   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion_raw  \\\n",
      "0                                          0.261097   \n",
      "1                                          0.107050   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion_raw  \\\n",
      "0                                           0.313316    \n",
      "1                                           0.164491    \n",
      "\n",
      "   selected_2_chicago_bias_raw  selected_2_chicago_male_score  \\\n",
      "0                     0.052219                       0.253493   \n",
      "1                     0.057441                       0.118771   \n",
      "\n",
      "   selected_2_chicago_female_score  \\\n",
      "0                         0.297996   \n",
      "1                         0.167062   \n",
      "\n",
      "   selected_2_chicago_male_score_neutral_faces  \\\n",
      "0                                     0.002771   \n",
      "1                                     0.009771   \n",
      "\n",
      "   selected_2_chicago_female_score_neutral_faces  \n",
      "0                                       0.011685  \n",
      "1                                       0.008950  \n",
      "\n",
      "[2 rows x 54 columns]\n",
      "16000 train faces, 2000 validation faces, 2000 test faces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "learning rate: 0.0001\n",
      "epoch number: 3\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-0.0682, -0.2467, -0.0326,  0.1021, -0.0963, -0.0689, -0.1299, -0.1148,\n",
      "        -0.1570,  0.0879, -0.1510, -0.1032, -0.0826, -0.0850,  0.1353,  0.2289,\n",
      "         0.1049, -0.0336,  0.1224,  0.0671,  0.0984, -0.1542, -0.0590, -0.0627,\n",
      "        -0.2030,  0.1251,  0.0261,  0.0251, -0.0103,  0.1647,  0.0846,  0.0437,\n",
      "        -0.1193,  0.0742,  0.1851,  0.0720,  0.1355,  0.0826, -0.0372,  0.0307,\n",
      "         0.1669,  0.0226,  0.1014,  0.0451,  0.0153, -0.1962, -0.0121, -0.2001,\n",
      "        -0.2311, -0.1966, -0.1237, -0.1553,  0.0052, -0.1199, -0.0389, -0.0561,\n",
      "         0.2248, -0.0022, -0.1237,  0.0840, -0.1745, -0.0412, -0.0028,  0.2141],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 5.8006e-02, -3.3233e-02],\n",
      "        [ 4.7958e-01, -1.3892e-01],\n",
      "        [-2.4646e-02, -2.3533e-01],\n",
      "        [ 4.0025e-01, -1.5752e-01],\n",
      "        [-5.0850e-02, -8.7275e-02],\n",
      "        [ 2.4858e-02, -3.0686e-01],\n",
      "        [-3.9483e-02, -2.3155e-01],\n",
      "        [ 3.6052e-01, -6.1450e-02],\n",
      "        [ 9.5986e-02,  3.6920e-03],\n",
      "        [ 1.0042e-01, -1.0920e-01],\n",
      "        [ 8.8136e-02,  4.8133e-02],\n",
      "        [ 2.3906e-01,  1.2193e-02],\n",
      "        [ 7.3029e-03, -4.7918e-02],\n",
      "        [-1.5212e-01, -1.3353e-01],\n",
      "        [ 2.0208e-01, -4.5180e-02],\n",
      "        [ 1.8425e-01,  5.6558e-02],\n",
      "        [-3.9262e-04,  2.6398e-03],\n",
      "        [ 5.4510e-02, -1.2290e-01],\n",
      "        [-1.7130e-03, -1.5970e-01],\n",
      "        [ 3.0172e-01,  3.3005e-02],\n",
      "        [-3.0254e-02, -1.6695e-01],\n",
      "        [-1.5945e-02, -1.0067e-01],\n",
      "        [ 5.4233e-02, -3.7334e-01],\n",
      "        [-6.5737e-02, -1.7719e-01],\n",
      "        [-2.4434e-01,  1.7830e-02],\n",
      "        [-1.0613e-01, -1.7671e-01],\n",
      "        [ 5.1044e-02, -1.2888e-01],\n",
      "        [ 2.7852e-02,  2.9590e-02],\n",
      "        [-1.3618e-01,  6.7793e-02],\n",
      "        [ 2.9324e-01, -6.7268e-02],\n",
      "        [ 3.5615e-01, -5.2867e-02],\n",
      "        [-2.5573e-01,  7.8502e-02],\n",
      "        [ 2.1455e-02,  1.2163e-01],\n",
      "        [ 6.9034e-02,  2.6733e-02],\n",
      "        [ 6.4753e-02, -4.4081e-02],\n",
      "        [ 1.8061e-01,  2.4064e-02],\n",
      "        [ 1.6473e-03, -2.6472e-01],\n",
      "        [ 1.5100e-01, -2.5570e-01],\n",
      "        [-1.9962e-01, -2.3499e-01],\n",
      "        [ 2.8395e-01, -2.2174e-01],\n",
      "        [ 2.4442e-01, -6.3378e-02],\n",
      "        [ 5.7541e-02, -3.3395e-02],\n",
      "        [ 1.4890e-01, -2.6052e-02],\n",
      "        [ 7.8189e-03, -1.2813e-01],\n",
      "        [ 8.2055e-02, -1.0396e-01],\n",
      "        [-7.4268e-03, -2.8639e-01],\n",
      "        [-2.7228e-01, -9.9641e-02],\n",
      "        [ 1.5289e-01, -1.4276e-01],\n",
      "        [ 5.0667e-03, -8.0664e-02],\n",
      "        [-1.6220e-01, -1.6528e-01],\n",
      "        [-9.3529e-02, -2.3488e-01],\n",
      "        [ 1.5411e-01, -6.7590e-02],\n",
      "        [ 8.4470e-03,  4.2903e-02],\n",
      "        [-3.5771e-03, -7.7688e-02],\n",
      "        [ 1.9649e-01, -5.9339e-02],\n",
      "        [ 1.3441e-01, -3.3680e-01],\n",
      "        [ 9.2327e-02,  1.0493e-01],\n",
      "        [ 1.8254e-02, -2.2456e-01],\n",
      "        [-2.7776e-01, -4.1825e-01],\n",
      "        [-5.9550e-02, -2.0926e-01],\n",
      "        [-2.1766e-02, -2.9149e-01],\n",
      "        [-9.2076e-02, -3.7352e-01],\n",
      "        [ 4.4378e-02,  8.7114e-02],\n",
      "        [ 6.6330e-02, -1.0756e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.7229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 0: [250|250], class loss:0.5196781754493713, class accuracy: 81.0375, domain loss: 0.6852341890335083, domain accuracy: 50.01875\n",
      "Testing epoch, class loss:0.32252645399421453,  class accuracy: 86.7, mAP: 0.8855898990508909, domain loss: 0.6914912015199661, domain accuracy: 65.7\n",
      "\n",
      "Training epoch 1: [250|250], class loss:0.46431487798690796, class accuracy: 89.15, domain loss: 0.6763211488723755, domain accuracy: 56.975\n",
      "Testing epoch, class loss:0.3418913600035012,  class accuracy: 86.15, mAP: 0.8849432214764449, domain loss: 0.6648759450763464, domain accuracy: 62.25\n",
      "\n",
      "Training epoch 2: [250|250], class loss:0.4575275182723999, class accuracy: 89.24375, domain loss: 0.7162922024726868, domain accuracy: 58.075\n",
      "Testing epoch, class loss:0.3418913600035012,  class accuracy: 86.15, mAP: 0.8849432214764449, domain loss: 0.6591297443956137, domain accuracy: 63.5\n",
      "\n",
      "learning rate: 1e-05\n",
      "epoch number: 6\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 1.0820,  1.3729, -2.9778,  0.7977, -0.6453, -1.3887,  0.3811,  3.0005,\n",
      "         2.5811, -0.7637,  4.4446, -1.3485, -1.2495, -2.6659, -0.6425,  0.7528,\n",
      "        -0.9856, -5.9697,  1.3597,  1.3493, -0.5427,  2.0841, -1.2146, -4.0902,\n",
      "         3.6705, -1.7491, -1.3467, -2.7144, -3.1106, -0.6665,  1.0282,  2.5000,\n",
      "        -4.2065,  1.3635, -1.2740, -1.0849,  1.1709,  2.6971, -1.0570,  2.9450,\n",
      "        -4.6228, -1.1724,  2.4316, -0.8660, -1.2108, -2.5565, -1.0126, -4.1702,\n",
      "         1.1604, -3.0530, -1.9101, -0.2577, -3.7184,  5.3892, -2.0541, -0.8671,\n",
      "        -1.3336, -0.6195, -1.4760, -0.3882,  2.0094, -1.5032, -2.7941, -2.1662],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.4142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 1.3019e-01, -2.0318e-01],\n",
      "        [ 3.8391e-02,  1.8557e-01],\n",
      "        [-7.1908e-01,  1.1013e-01],\n",
      "        [-4.2614e-02, -3.6781e-03],\n",
      "        [-2.4493e-01,  1.9356e-01],\n",
      "        [-2.0732e-01, -2.5069e-01],\n",
      "        [-6.8231e-02, -8.6389e-02],\n",
      "        [-1.3856e-01, -4.4849e-01],\n",
      "        [-2.8007e-01,  6.8263e-02],\n",
      "        [-2.7373e-01,  1.1497e-01],\n",
      "        [ 1.8537e-01, -5.2928e-01],\n",
      "        [-1.7627e-01, -2.9597e-01],\n",
      "        [-3.3911e-01,  1.4327e-01],\n",
      "        [-4.4888e-01, -3.5091e-01],\n",
      "        [-2.3286e-01, -1.2637e-01],\n",
      "        [-1.0832e-02,  1.1561e-01],\n",
      "        [-1.6225e-01, -1.1084e-01],\n",
      "        [-3.2824e-01, -2.2761e-01],\n",
      "        [-9.1165e-02,  4.9121e-01],\n",
      "        [ 4.0520e-02, -1.8483e-01],\n",
      "        [-1.2169e-01, -1.1615e-01],\n",
      "        [ 1.2984e-01, -6.8397e-02],\n",
      "        [ 2.0506e-01, -2.2643e-01],\n",
      "        [-8.8078e-01,  1.1296e-01],\n",
      "        [ 3.0182e-01, -2.4702e-01],\n",
      "        [-5.6658e-01, -2.1438e-02],\n",
      "        [-2.5862e-01,  1.5563e-01],\n",
      "        [-3.3647e-01, -5.7085e-02],\n",
      "        [-5.1839e-01, -1.1294e-01],\n",
      "        [-2.7279e-02, -1.4962e-02],\n",
      "        [-2.7937e-02,  7.9509e-02],\n",
      "        [ 2.0326e-01,  1.1197e-01],\n",
      "        [-5.7463e-01, -6.5405e-02],\n",
      "        [-6.9070e-02,  1.1138e-01],\n",
      "        [-7.1360e-02, -1.9774e-01],\n",
      "        [-2.9484e-01,  7.1245e-02],\n",
      "        [ 5.3851e-02, -1.8157e-01],\n",
      "        [-1.9651e-01, -1.8747e-01],\n",
      "        [ 5.9044e-03, -1.9203e-01],\n",
      "        [ 3.6160e-01, -3.8718e-02],\n",
      "        [-7.4664e-01, -8.1140e-01],\n",
      "        [-1.0438e-01, -4.3220e-01],\n",
      "        [ 2.9459e-01, -3.1383e-01],\n",
      "        [-2.7993e-01, -1.5961e-01],\n",
      "        [ 1.4379e-01, -4.1809e-01],\n",
      "        [-2.0064e-01, -5.2389e-03],\n",
      "        [-3.7097e-01, -1.4110e-02],\n",
      "        [-2.8868e-01,  2.1137e-01],\n",
      "        [-3.1911e-04,  2.4335e-02],\n",
      "        [-1.5732e-01, -1.8146e-01],\n",
      "        [-1.9526e-01,  5.6836e-02],\n",
      "        [ 1.0741e-01, -1.5728e-01],\n",
      "        [-3.3633e-01,  2.7128e-01],\n",
      "        [ 5.5918e-01, -8.6331e-02],\n",
      "        [-4.1266e-01, -3.3073e-01],\n",
      "        [-1.1259e-01,  2.4664e-01],\n",
      "        [-5.0910e-01, -2.4317e-02],\n",
      "        [-5.9504e-02, -1.6671e-02],\n",
      "        [-1.5600e-01, -7.8748e-02],\n",
      "        [-1.3892e-01, -1.1343e-01],\n",
      "        [-2.4230e-01,  1.4025e-01],\n",
      "        [-1.6156e-01,  1.4112e-01],\n",
      "        [-6.7567e-01, -5.2432e-01],\n",
      "        [-3.0445e-01, -1.3864e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6987, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 3: [250|250], class loss:0.5511778593063354, class accuracy: 90.78125, domain loss: 0.6929265260696411, domain accuracy: 52.64375\n",
      "Testing epoch, class loss:0.32798135792836547,  class accuracy: 87.15, mAP: 0.8917643582652837, domain loss: 0.6909925267100334, domain accuracy: 58.25\n",
      "\n",
      "Training epoch 4: [250|250], class loss:0.5181559324264526, class accuracy: 93.9625, domain loss: 0.7128536105155945, domain accuracy: 54.79375\n",
      "Testing epoch, class loss:0.32952107209712267,  class accuracy: 87.45, mAP: 0.8916577266154991, domain loss: 0.6803744304925203, domain accuracy: 62.3\n",
      "\n",
      "Training epoch 5: [250|250], class loss:0.5098693370819092, class accuracy: 93.95625, domain loss: 0.6849523782730103, domain accuracy: 55.75\n",
      "Testing epoch, class loss:0.32952107209712267,  class accuracy: 87.45, mAP: 0.8916577266154991, domain loss: 0.6779935639351606, domain accuracy: 62.3\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 0.5397,  2.8168, -6.2142,  3.6342, -0.8901, -2.0006, -0.5361,  4.0237,\n",
      "         3.0026, -2.4272,  4.1672, -3.5566, -2.9289, -5.7041, -3.0378,  2.9268,\n",
      "        -2.8250, -5.2994,  2.0159,  1.9313, -3.8521,  2.3151, -4.0454, -4.5305,\n",
      "         3.9269, -2.7789, -5.5783, -4.2201, -5.3046, -3.1408,  3.2887,  3.3814,\n",
      "        -6.4054,  1.7215, -3.9453,  0.5556, -0.0288,  4.4588, -3.9870,  4.1639,\n",
      "        -5.8493, -1.8044,  3.2854, -1.6788, -1.7536, -3.3853, -1.9760, -6.9936,\n",
      "        -1.9474, -5.4256, -4.1869, -2.1693, -4.1211,  5.9446, -3.5335, -0.7645,\n",
      "        -2.8075, -0.1744, -5.2695, -3.2797,  0.8548, -4.8464, -4.6525, -3.8651],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.3036, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[-0.0593, -0.0492],\n",
      "        [ 0.3106,  0.0715],\n",
      "        [-0.2363, -0.3114],\n",
      "        [-0.0837, -0.1632],\n",
      "        [-0.1142, -0.0630],\n",
      "        [-0.3823, -0.3824],\n",
      "        [-0.1828, -0.2254],\n",
      "        [ 0.1802, -0.2481],\n",
      "        [ 0.0397,  0.1309],\n",
      "        [ 0.0735,  0.0046],\n",
      "        [ 0.0727,  0.2577],\n",
      "        [-0.2331, -0.3437],\n",
      "        [-0.3115, -0.3663],\n",
      "        [-0.7975, -0.5405],\n",
      "        [-0.3020, -0.2573],\n",
      "        [-0.0857,  0.0586],\n",
      "        [ 0.0113, -0.1279],\n",
      "        [-0.7730, -0.7054],\n",
      "        [ 0.1410, -0.0952],\n",
      "        [ 0.1730, -0.0942],\n",
      "        [-0.3393, -0.4414],\n",
      "        [ 0.0032, -0.3816],\n",
      "        [-0.4978, -0.1101],\n",
      "        [-0.2900, -0.4478],\n",
      "        [-0.0529,  0.0129],\n",
      "        [ 0.0499,  0.5173],\n",
      "        [-0.6563,  0.1098],\n",
      "        [-0.2520, -0.3676],\n",
      "        [-0.3379, -0.5681],\n",
      "        [-0.5499, -0.5678],\n",
      "        [-0.0468, -0.2693],\n",
      "        [ 0.2579,  0.2987],\n",
      "        [-0.6986, -0.4604],\n",
      "        [ 0.0663,  0.1812],\n",
      "        [-0.1657, -0.1227],\n",
      "        [ 0.0462,  0.0056],\n",
      "        [-0.0479, -0.0149],\n",
      "        [-0.1907, -0.3783],\n",
      "        [-0.2231, -0.2401],\n",
      "        [ 0.3038,  0.3594],\n",
      "        [-0.1694, -0.0607],\n",
      "        [-0.1550, -0.0098],\n",
      "        [ 0.2212, -0.0495],\n",
      "        [ 0.0212, -0.0738],\n",
      "        [ 0.1275,  0.1955],\n",
      "        [-0.6056,  0.0430],\n",
      "        [-0.3274, -0.1095],\n",
      "        [-0.7110, -0.1150],\n",
      "        [-0.2476, -0.0645],\n",
      "        [-0.3005, -0.3275],\n",
      "        [-0.5482, -0.1970],\n",
      "        [-0.0558, -0.0067],\n",
      "        [-0.0019,  0.2704],\n",
      "        [-0.2966, -0.4323],\n",
      "        [-0.1634, -0.2690],\n",
      "        [-0.1305, -0.1570],\n",
      "        [-0.5755, -0.5062],\n",
      "        [-0.0314, -0.1122],\n",
      "        [-0.6147, -0.2874],\n",
      "        [ 0.1965,  0.2656],\n",
      "        [-0.0242, -0.1183],\n",
      "        [-0.5704, -0.3883],\n",
      "        [-0.3737, -0.6770],\n",
      "        [-0.5366, -0.4250]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 6: [250|250], class loss:0.34337127208709717, class accuracy: 94.45625, domain loss: 0.7101746797561646, domain accuracy: 51.43125\n",
      "Testing epoch, class loss:0.3907580457162112,  class accuracy: 86.65, mAP: 0.8638072364620089, domain loss: 0.6890669632703066, domain accuracy: 63.1\n",
      "\n",
      "Training epoch 7: [250|250], class loss:0.29770708084106445, class accuracy: 97.35625, domain loss: 0.7053975462913513, domain accuracy: 55.4375\n",
      "Testing epoch, class loss:0.3972924305126071,  class accuracy: 86.8, mAP: 0.8634317121396905, domain loss: 0.6843987535685301, domain accuracy: 59.75\n",
      "\n",
      "Training epoch 8: [250|250], class loss:0.3217272460460663, class accuracy: 97.36875, domain loss: 0.6723083853721619, domain accuracy: 55.70625\n",
      "Testing epoch, class loss:0.3972924305126071,  class accuracy: 86.8, mAP: 0.8634317121396905, domain loss: 0.6822298187762499, domain accuracy: 61.1\n",
      "\n",
      "learning rate: 1e-06\n",
      "epoch number: 12\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-3.3426,  4.1965, -5.4187,  5.5381, -1.2563, -2.9276, -2.7636,  4.6576,\n",
      "         4.2263, -4.0577,  4.9649, -5.5413, -6.2198, -6.2960, -4.4159,  4.1395,\n",
      "        -2.8705, -5.3487,  3.3709,  2.7959, -3.8850,  3.5743, -5.9222, -4.3912,\n",
      "         4.6317, -3.0671, -5.7185, -5.4934, -8.9813, -4.5244,  5.0896,  4.2010,\n",
      "        -8.2186,  0.8808, -2.6608,  4.4324, -4.4437,  6.1357, -4.8871,  4.3856,\n",
      "        -5.4178, -1.6940,  4.2269, -1.7636, -1.2681, -3.1624,  0.4098, -6.0560,\n",
      "        -3.8714, -5.6956, -5.0799, -2.8778, -4.1968,  5.1342, -3.8795, -0.8403,\n",
      "        -2.6980,  1.5666, -7.6426, -3.9713, -2.5022, -7.7581, -5.0183, -3.6790],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.1643, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[-3.1705e-01, -3.1757e-01],\n",
      "        [ 2.6610e-01,  7.6762e-02],\n",
      "        [-4.0064e-01, -5.7595e-01],\n",
      "        [-3.5213e-01, -1.6459e-01],\n",
      "        [-3.6715e-02, -1.0404e-01],\n",
      "        [-2.2722e-01, -2.2105e-01],\n",
      "        [-4.3089e-01, -2.4383e-01],\n",
      "        [-1.5683e-01,  3.5565e-01],\n",
      "        [ 5.1642e-01,  8.4837e-02],\n",
      "        [-4.4568e-01, -5.1006e-01],\n",
      "        [ 4.6435e-02,  8.6195e-02],\n",
      "        [ 2.8746e-01,  3.9887e-02],\n",
      "        [-6.0720e-01, -2.4779e-01],\n",
      "        [-5.4316e-01, -7.5720e-02],\n",
      "        [-3.5183e-01, -6.0973e-01],\n",
      "        [ 1.6555e-01, -7.7251e-02],\n",
      "        [-2.3188e-01, -9.7049e-02],\n",
      "        [-4.6421e-01, -1.6587e-01],\n",
      "        [ 2.2741e-01,  2.2794e-02],\n",
      "        [ 1.7104e-01, -2.1499e-01],\n",
      "        [-1.0207e-02, -5.9698e-04],\n",
      "        [ 2.4209e-01, -6.7951e-02],\n",
      "        [-1.5339e-01, -1.3350e-01],\n",
      "        [-9.3694e-02, -5.3600e-02],\n",
      "        [ 1.8007e-01,  3.1601e-01],\n",
      "        [-3.5746e-01, -2.7766e-01],\n",
      "        [-5.6022e-01, -7.2698e-01],\n",
      "        [-4.9195e-01, -2.4146e-01],\n",
      "        [-7.5014e-01, -3.3509e-01],\n",
      "        [ 3.0015e-02, -3.8868e-02],\n",
      "        [-1.3658e-02,  1.6666e-01],\n",
      "        [-9.1323e-03,  1.2534e-02],\n",
      "        [-5.1508e-01, -6.4739e-01],\n",
      "        [-6.8523e-02, -2.5550e-01],\n",
      "        [ 1.6689e-03, -1.6603e-02],\n",
      "        [-7.6896e-02,  1.2826e-01],\n",
      "        [-1.6692e-01, -1.2942e-01],\n",
      "        [ 3.3125e-01,  1.3363e-01],\n",
      "        [-4.3589e-01, -2.1864e-01],\n",
      "        [ 2.2816e-01, -2.1342e-01],\n",
      "        [-6.5158e-02, -1.1996e-01],\n",
      "        [-7.1031e-02, -1.5945e-01],\n",
      "        [ 2.2879e-01, -4.2545e-01],\n",
      "        [-3.1342e-01, -2.5779e-01],\n",
      "        [-1.5683e-01, -2.0552e-01],\n",
      "        [-1.5798e-01, -1.1271e-01],\n",
      "        [-1.4755e-01, -1.9714e-01],\n",
      "        [-1.4303e-01,  2.4811e-03],\n",
      "        [-5.6500e-01, -4.5235e-01],\n",
      "        [-5.9013e-01, -2.9533e-01],\n",
      "        [-2.7387e-01, -9.9132e-02],\n",
      "        [-3.0232e-01, -1.5407e-01],\n",
      "        [-1.2065e-01, -2.7069e-01],\n",
      "        [-1.0943e-01, -5.7134e-01],\n",
      "        [-2.9367e-01, -4.4610e-01],\n",
      "        [-3.8716e-02,  3.8840e-02],\n",
      "        [-1.8785e-01,  8.0559e-02],\n",
      "        [ 6.6557e-02,  1.5164e-01],\n",
      "        [-4.4093e-01, -4.3896e-01],\n",
      "        [-3.7642e-01, -2.2186e-01],\n",
      "        [-3.9618e-01, -3.6514e-01],\n",
      "        [-4.2618e-01, -6.5670e-01],\n",
      "        [-7.1497e-01, -5.0064e-01],\n",
      "        [-1.5978e-01,  4.1029e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6671, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 9: [250|250], class loss:0.30833572149276733, class accuracy: 97.40625, domain loss: 0.6822234392166138, domain accuracy: 52.41875\n",
      "Testing epoch, class loss:0.3997234022244811,  class accuracy: 87.2, mAP: 0.865424754443797, domain loss: 0.6867424063384533, domain accuracy: 61.1\n",
      "\n",
      "Training epoch 10: [250|250], class loss:0.31191354990005493, class accuracy: 97.7375, domain loss: 0.6983858942985535, domain accuracy: 56.46875\n",
      "Testing epoch, class loss:0.40046996576711535,  class accuracy: 87.2, mAP: 0.8652652931526982, domain loss: 0.6810870226472616, domain accuracy: 61.5\n",
      "\n",
      "Training epoch 11: [250|250], class loss:0.3061051368713379, class accuracy: 97.73125, domain loss: 0.7122936248779297, domain accuracy: 56.375\n",
      "Testing epoch, class loss:0.40046996576711535,  class accuracy: 87.2, mAP: 0.8652652931526982, domain loss: 0.6806200966238976, domain accuracy: 61.45\n",
      "\n",
      "Training epoch 12: [250|250], class loss:0.28903433680534363, class accuracy: 97.7625, domain loss: 0.6686402559280396, domain accuracy: 52.65\n",
      "Testing epoch, class loss:0.4086487356107682,  class accuracy: 87.45, mAP: 0.8628858568965614, domain loss: 0.6877820696681738, domain accuracy: 56.5\n",
      "\n",
      "Training epoch 13: [250|250], class loss:0.2985847294330597, class accuracy: 98.10625, domain loss: 0.7012994885444641, domain accuracy: 55.39375\n",
      "Testing epoch, class loss:0.40930315922014415,  class accuracy: 87.45, mAP: 0.8628112428614927, domain loss: 0.6816641073673964, domain accuracy: 61.55\n",
      "\n",
      "Training epoch 14: [250|250], class loss:0.286403626203537, class accuracy: 98.10625, domain loss: 0.689853847026825, domain accuracy: 57.21875\n",
      "Testing epoch, class loss:0.40930315922014415,  class accuracy: 87.45, mAP: 0.8628112428614927, domain loss: 0.6811525821685791, domain accuracy: 61.4\n",
      "\n",
      "Training epoch 15: [250|250], class loss:0.2791566550731659, class accuracy: 98.14375, domain loss: 0.7075456976890564, domain accuracy: 51.875\n",
      "Testing epoch, class loss:0.41926269396208227,  class accuracy: 87.15, mAP: 0.859471350423408, domain loss: 0.6876471135765314, domain accuracy: 61.6\n",
      "\n",
      "Training epoch 16: [250|250], class loss:0.2783518433570862, class accuracy: 98.44375, domain loss: 0.7042812705039978, domain accuracy: 56.69375\n",
      "Testing epoch, class loss:0.4198764991015196,  class accuracy: 87.15, mAP: 0.8594105882233667, domain loss: 0.6818719152361155, domain accuracy: 61.05\n",
      "\n",
      "Training epoch 17: [250|250], class loss:0.2766374349594116, class accuracy: 98.4875, domain loss: 0.6770482659339905, domain accuracy: 56.73125\n",
      "Testing epoch, class loss:0.4198764991015196,  class accuracy: 87.15, mAP: 0.8594105882233667, domain loss: 0.6815868373960257, domain accuracy: 60.8\n",
      "\n",
      "Training epoch 18: [250|250], class loss:0.2436743825674057, class accuracy: 98.5125, domain loss: 0.6761299967765808, domain accuracy: 51.75625\n",
      "Testing epoch, class loss:0.43168131238780916,  class accuracy: 86.95, mAP: 0.8547282712000001, domain loss: 0.6882533673197031, domain accuracy: 54.95\n",
      "\n",
      "Training epoch 19: [250|250], class loss:0.25857067108154297, class accuracy: 98.725, domain loss: 0.6569642424583435, domain accuracy: 55.4375\n",
      "Testing epoch, class loss:0.4322390961460769,  class accuracy: 86.95, mAP: 0.8547276187763936, domain loss: 0.6824472174048424, domain accuracy: 60.75\n",
      "\n",
      "Training epoch 20: [250|250], class loss:0.26221752166748047, class accuracy: 98.725, domain loss: 0.6874063014984131, domain accuracy: 56.38125\n",
      "Testing epoch, class loss:0.4322390961460769,  class accuracy: 86.95, mAP: 0.8547276187763936, domain loss: 0.682040560990572, domain accuracy: 60.5\n",
      "Finish training epoch 21, dev class loss: 0.4322390961460769, dev doamin loss: 0.682040560990572, dev mAP: 0.8547276187763936,domain_accuracy: 60.5, time used: 0:51:38.147952\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "   model_random_state  test_accuracy  test_gender_accuracy  \\\n",
      "0                   1         0.8450                0.5985   \n",
      "1                   2         0.8565                0.6160   \n",
      "2                   3         0.8630                0.6045   \n",
      "\n",
      "   test_male_true_proportion  test_female_true_proportion  \\\n",
      "0                   0.302895                     0.398162   \n",
      "1                   0.319911                     0.409712   \n",
      "2                   0.295570                     0.356340   \n",
      "\n",
      "   test_male_predicted_proportion  test_female_predicted_proportion  \\\n",
      "0                        0.290275                          0.381317   \n",
      "1                        0.275913                          0.379363   \n",
      "2                        0.286129                          0.367576   \n",
      "\n",
      "   test_male_average_score  test_female_average_score  \\\n",
      "0                 0.297638                   0.378439   \n",
      "1                 0.280973                   0.386162   \n",
      "2                 0.286778                   0.365670   \n",
      "\n",
      "   balanced_chicago_accuracy  ...  \\\n",
      "0                   0.960924  ...   \n",
      "1                   0.914742  ...   \n",
      "2                   0.928952  ...   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion  \\\n",
      "0                                      0.342037   \n",
      "1                                      0.344648   \n",
      "2                                      0.334204   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion  selected_2_chicago_bias  \\\n",
      "0                                        0.383812                 0.041775   \n",
      "1                                        0.381201                 0.036554   \n",
      "2                                        0.391645                 0.057441   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion_raw  \\\n",
      "0                                          0.261097   \n",
      "1                                          0.107050   \n",
      "2                                          0.080940   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion_raw  \\\n",
      "0                                           0.313316    \n",
      "1                                           0.164491    \n",
      "2                                           0.177546    \n",
      "\n",
      "   selected_2_chicago_bias_raw  selected_2_chicago_male_score  \\\n",
      "0                     0.052219                       0.253493   \n",
      "1                     0.057441                       0.118771   \n",
      "2                     0.096606                       0.096812   \n",
      "\n",
      "   selected_2_chicago_female_score  \\\n",
      "0                         0.297996   \n",
      "1                         0.167062   \n",
      "2                         0.175278   \n",
      "\n",
      "   selected_2_chicago_male_score_neutral_faces  \\\n",
      "0                                     0.002771   \n",
      "1                                     0.009771   \n",
      "2                                     0.002173   \n",
      "\n",
      "   selected_2_chicago_female_score_neutral_faces  \n",
      "0                                       0.011685  \n",
      "1                                       0.008950  \n",
      "2                                       0.005565  \n",
      "\n",
      "[3 rows x 54 columns]\n",
      "16000 train faces, 2000 validation faces, 2000 test faces\n",
      "\n",
      "learning rate: 0.0001\n",
      "epoch number: 3\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-0.1264, -0.2571, -0.2201, -0.3751,  0.0946,  0.0428, -0.2078,  0.0076,\n",
      "        -0.2603, -0.3154, -0.2784, -0.2637,  0.0946, -0.1158, -0.0248, -0.2974,\n",
      "         0.1095, -0.0872,  0.1220, -0.3087, -0.0991, -0.3182, -0.1722, -0.3719,\n",
      "         0.2056, -0.2454,  0.0278, -0.0875,  0.0339, -0.2511, -0.1135, -0.2811,\n",
      "        -0.2852, -0.3377, -0.3343, -0.0588, -0.4400, -0.0810, -0.0535, -0.2260,\n",
      "         0.1503,  0.0107, -0.1379, -0.0839, -0.3962, -0.0663, -0.1988, -0.0129,\n",
      "        -0.0716, -0.1427, -0.0436, -0.1166, -0.1105, -0.0259, -0.1748, -0.1462,\n",
      "        -0.3725, -0.3281, -0.1334,  0.0808, -0.1738, -0.0340, -0.2287, -0.5689],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.6728, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 5.0070e-02,  1.3710e-01],\n",
      "        [-2.0455e-01, -1.0324e-01],\n",
      "        [ 3.1824e-01, -1.7410e-01],\n",
      "        [-1.3909e-01,  3.9297e-02],\n",
      "        [ 8.7860e-03,  8.9811e-02],\n",
      "        [ 1.3113e-01, -7.7534e-03],\n",
      "        [ 3.9185e-02, -1.4170e-01],\n",
      "        [ 1.9293e-01,  1.2212e-01],\n",
      "        [-2.7833e-04,  1.3744e-01],\n",
      "        [ 1.6672e-01,  2.5066e-01],\n",
      "        [ 2.4718e-01, -5.0389e-02],\n",
      "        [-1.0439e-01, -4.8253e-02],\n",
      "        [ 5.6146e-02, -1.9068e-01],\n",
      "        [ 3.1297e-01, -5.0129e-02],\n",
      "        [ 3.6883e-02, -6.9539e-02],\n",
      "        [ 3.0929e-01, -1.4960e-01],\n",
      "        [-6.0882e-02,  2.2007e-01],\n",
      "        [ 1.4607e-01, -1.6152e-01],\n",
      "        [ 1.4271e-01, -3.0798e-02],\n",
      "        [-1.5407e-01,  2.6010e-02],\n",
      "        [ 1.1205e-01,  2.2101e-01],\n",
      "        [-1.7638e-01,  1.3038e-01],\n",
      "        [-1.0420e-02,  8.9674e-02],\n",
      "        [ 1.6965e-01,  2.1425e-01],\n",
      "        [-2.7684e-01, -1.4820e-01],\n",
      "        [ 2.1277e-01, -2.5336e-02],\n",
      "        [ 1.8903e-01,  1.9964e-01],\n",
      "        [-5.2589e-02,  5.9635e-02],\n",
      "        [ 1.3951e-01,  9.3834e-02],\n",
      "        [-3.8366e-02,  1.0975e-01],\n",
      "        [ 1.7632e-01, -6.0249e-02],\n",
      "        [-1.2248e-01, -1.1892e-01],\n",
      "        [ 8.9904e-02,  1.0619e-01],\n",
      "        [ 1.0817e-01, -2.8953e-02],\n",
      "        [ 1.2291e-01,  2.1263e-01],\n",
      "        [-9.6101e-02,  8.5664e-02],\n",
      "        [-6.2289e-02,  9.9646e-03],\n",
      "        [-1.3793e-01, -2.2378e-01],\n",
      "        [ 6.2608e-02,  2.1088e-01],\n",
      "        [ 4.0482e-02,  5.9475e-02],\n",
      "        [ 1.0692e-01, -2.8386e-02],\n",
      "        [-4.8849e-02,  2.4003e-03],\n",
      "        [-1.4551e-01,  1.7787e-01],\n",
      "        [ 4.1107e-02,  7.5276e-02],\n",
      "        [ 2.7328e-01, -2.3359e-01],\n",
      "        [-2.4165e-01,  2.8433e-01],\n",
      "        [-4.8786e-02, -1.2399e-01],\n",
      "        [-1.8846e-02, -4.1637e-02],\n",
      "        [ 1.0030e-01,  6.6628e-02],\n",
      "        [ 2.2142e-01,  6.4044e-02],\n",
      "        [-2.4627e-01,  4.3123e-01],\n",
      "        [-7.3544e-02, -1.0730e-01],\n",
      "        [ 7.6076e-02, -2.7911e-02],\n",
      "        [ 2.0925e-02, -1.6763e-01],\n",
      "        [ 1.2048e-01,  1.7337e-01],\n",
      "        [ 7.0497e-02, -2.0825e-01],\n",
      "        [-1.6411e-01,  1.0518e-02],\n",
      "        [-2.4266e-03, -2.5641e-02],\n",
      "        [ 5.1434e-02, -1.3287e-01],\n",
      "        [-5.5939e-02, -2.8628e-02],\n",
      "        [-1.0321e-01,  1.3856e-01],\n",
      "        [ 2.4199e-01, -3.6073e-01],\n",
      "        [ 3.2239e-01,  4.6418e-02],\n",
      "        [ 1.6334e-02,  3.4583e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6676, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0: [250|250], class loss:0.39034467935562134, class accuracy: 81.34375, domain loss: 0.7019896507263184, domain accuracy: 50.5625\n",
      "Testing epoch, class loss:0.33968701399862766,  class accuracy: 85.95, mAP: 0.8636525291880549, domain loss: 0.6961531732231379, domain accuracy: 39.4\n",
      "\n",
      "Training epoch 1: [250|250], class loss:0.3693617284297943, class accuracy: 87.80625, domain loss: 0.7104107141494751, domain accuracy: 57.6875\n",
      "Testing epoch, class loss:0.3416293174959719,  class accuracy: 85.55, mAP: 0.8643296372057307, domain loss: 0.6752764228731394, domain accuracy: 52.15\n",
      "\n",
      "Training epoch 2: [250|250], class loss:0.3685336709022522, class accuracy: 87.76875, domain loss: 0.7227420806884766, domain accuracy: 57.975\n",
      "Testing epoch, class loss:0.3416293174959719,  class accuracy: 85.55, mAP: 0.8643296372057307, domain loss: 0.6741720736026764, domain accuracy: 47.4\n",
      "\n",
      "learning rate: 1e-05\n",
      "epoch number: 6\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-1.6763,  6.0353, -1.6094, -2.2617, -1.8309,  1.7956, -1.6963, -2.5139,\n",
      "        -1.3967, -2.9587, -1.9910, -4.0298, -2.6785, -2.1606, -0.2810, -2.8802,\n",
      "         0.0752, -2.0831, -1.2962, -1.8738, -0.7868, -3.1250, -4.2565,  6.8014,\n",
      "        -1.4783, -1.0544, -4.1657,  2.8404, -1.3301,  0.1837, -1.1739, -4.5531,\n",
      "        -3.9012,  3.2015, -3.5280, -2.1566,  1.5671,  2.2243, -3.7563, -2.3066,\n",
      "        -1.4232,  0.6201, -4.2087, -1.8541, -0.9885, -2.8187, -2.3108, -0.9915,\n",
      "        -2.2235, -1.1720, -2.0693, -2.9346, -4.2080,  3.6047, -2.9251, -1.8356,\n",
      "        -0.5432, -3.0740,  1.1452,  4.4066, -4.3937, -1.8147,  0.0734, -1.9643],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.4184, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 2.4487e-01,  1.1414e-01],\n",
      "        [ 5.0701e-01, -1.6076e+00],\n",
      "        [ 4.0642e-01, -3.4614e-01],\n",
      "        [-1.7375e-01,  2.3218e-02],\n",
      "        [ 3.6007e-01, -1.1785e-01],\n",
      "        [ 4.0131e-01, -2.1193e-01],\n",
      "        [ 1.3116e-01, -1.9288e-01],\n",
      "        [ 2.1500e-01,  5.6594e-02],\n",
      "        [ 9.0512e-01, -7.8025e-01],\n",
      "        [-2.1665e-01, -7.9475e-02],\n",
      "        [ 2.4875e-01,  2.3437e-01],\n",
      "        [ 1.1957e-01,  1.4226e-01],\n",
      "        [ 3.0916e-02,  1.5219e-01],\n",
      "        [-1.0410e-01,  9.2933e-02],\n",
      "        [ 6.9647e-02, -2.1133e-01],\n",
      "        [ 3.7231e-01, -8.0978e-02],\n",
      "        [ 1.2072e-01, -6.8908e-02],\n",
      "        [ 1.8476e-01, -2.5984e-01],\n",
      "        [-5.1157e-02, -2.1168e-01],\n",
      "        [-8.8598e-02,  3.0576e-01],\n",
      "        [ 1.3951e-01, -2.3715e-01],\n",
      "        [ 2.0410e-01, -1.9713e-01],\n",
      "        [ 6.9223e-01,  1.2593e-01],\n",
      "        [-6.6437e-02, -5.6984e-01],\n",
      "        [-2.0309e-01,  7.6552e-02],\n",
      "        [-1.4449e-02,  1.5818e-01],\n",
      "        [-4.6792e-02,  2.0988e-01],\n",
      "        [ 1.8807e-01, -1.5220e-01],\n",
      "        [ 3.0788e-01,  2.7436e-02],\n",
      "        [ 1.0327e-01, -1.6337e-01],\n",
      "        [ 1.6471e-01, -3.2765e-01],\n",
      "        [-4.3874e-03,  4.7529e-01],\n",
      "        [ 3.4581e-01, -1.3744e-02],\n",
      "        [ 2.2254e-01, -5.0385e-01],\n",
      "        [ 2.8165e-01,  4.5413e-02],\n",
      "        [ 3.4041e-02,  3.4381e-01],\n",
      "        [ 8.7038e-02, -6.3418e-01],\n",
      "        [-1.3703e-01, -1.1749e-01],\n",
      "        [ 6.4205e-02, -1.6140e-01],\n",
      "        [-5.5735e-04, -5.5816e-02],\n",
      "        [-2.2192e-01,  7.3635e-02],\n",
      "        [ 1.2123e-01, -1.0631e-01],\n",
      "        [ 3.9523e-01, -1.9259e-01],\n",
      "        [-1.0014e-01,  3.7633e-01],\n",
      "        [ 5.3179e-02, -8.0551e-02],\n",
      "        [ 1.6857e-01, -1.7428e-01],\n",
      "        [ 5.8864e-02,  1.3772e-01],\n",
      "        [-1.6152e-02,  3.5871e-02],\n",
      "        [-4.8491e-02, -2.2664e-01],\n",
      "        [-1.0469e-01,  1.4344e-01],\n",
      "        [ 9.5141e-03,  1.5953e-01],\n",
      "        [ 2.0136e-01, -3.9535e-01],\n",
      "        [-3.0876e-01, -1.6585e-01],\n",
      "        [ 6.0472e-02, -6.2049e-01],\n",
      "        [ 2.3152e-01, -3.9927e-01],\n",
      "        [ 5.3857e-01, -1.5841e-01],\n",
      "        [-4.3488e-02,  3.9874e-02],\n",
      "        [ 2.5443e-02, -6.2836e-02],\n",
      "        [ 5.0314e-02, -2.9658e-01],\n",
      "        [-7.9602e-02, -5.9590e-01],\n",
      "        [ 7.3508e-01,  3.7128e-02],\n",
      "        [ 1.3734e-01, -3.2055e-02],\n",
      "        [ 6.6294e-03, -3.0015e-02],\n",
      "        [ 1.9133e-01, -1.2011e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 3: [250|250], class loss:0.41731348633766174, class accuracy: 90.375, domain loss: 0.6891322135925293, domain accuracy: 52.2625\n",
      "Testing epoch, class loss:0.36948701133951545,  class accuracy: 86.45, mAP: 0.8626795831015371, domain loss: 0.6902906317263842, domain accuracy: 52.75\n",
      "\n",
      "Training epoch 4: [250|250], class loss:0.38045236468315125, class accuracy: 93.63125, domain loss: 0.6813080310821533, domain accuracy: 55.65625\n",
      "Testing epoch, class loss:0.3572555957362056,  class accuracy: 86.45, mAP: 0.8630910510970491, domain loss: 0.6819708719849586, domain accuracy: 61.5\n",
      "\n",
      "Training epoch 5: [250|250], class loss:0.38511914014816284, class accuracy: 93.63125, domain loss: 0.6481732130050659, domain accuracy: 56.86875\n",
      "Testing epoch, class loss:0.3572555957362056,  class accuracy: 86.45, mAP: 0.8630910510970491, domain loss: 0.680926701053977, domain accuracy: 61.5\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-2.6405,  6.7153, -3.7662, -3.7875, -1.9844,  4.7978, -2.9361, -5.1505,\n",
      "        -2.4473, -6.1505, -0.9396, -7.0459, -4.2197, -3.2010,  2.6409, -4.9349,\n",
      "         3.3678, -4.1893, -2.7322, -2.5944, -0.9576, -4.4374, -5.2498,  7.7670,\n",
      "        -2.3297, -2.3491, -6.0720,  4.1246,  0.8186,  3.0595, -1.9699, -4.5099,\n",
      "        -6.4497,  6.0406, -3.7483, -3.5013,  3.3351,  0.8600, -5.4574, -3.0088,\n",
      "        -2.3968,  5.5824, -4.5253, -3.7076, -2.0562, -4.2639, -3.9789,  0.5569,\n",
      "        -2.0156, -0.9923, -3.2254, -4.7796, -5.2817,  4.9520, -3.6853, -3.2271,\n",
      "         2.8357, -3.6069,  1.5592,  6.5672, -4.2038, -2.2500,  3.2916, -2.7842],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.2897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[-0.0021,  0.0335],\n",
      "        [ 0.7631, -0.2307],\n",
      "        [-0.1200, -0.1021],\n",
      "        [ 0.0139,  0.0033],\n",
      "        [ 0.0176,  0.0373],\n",
      "        [-0.3506, -0.6475],\n",
      "        [ 0.3089,  0.1024],\n",
      "        [-0.0283,  0.0898],\n",
      "        [ 0.0752,  0.1303],\n",
      "        [-0.2081,  0.2587],\n",
      "        [ 0.0272,  0.1865],\n",
      "        [-0.0575,  0.2095],\n",
      "        [-0.1929, -0.0739],\n",
      "        [-0.0074,  0.2116],\n",
      "        [-0.0788, -0.1521],\n",
      "        [ 0.0800,  0.5224],\n",
      "        [ 0.1757, -0.0232],\n",
      "        [ 0.1582,  0.3836],\n",
      "        [-0.1892,  0.1919],\n",
      "        [-0.1791,  0.2247],\n",
      "        [ 0.0125,  0.2195],\n",
      "        [ 0.0372,  0.1511],\n",
      "        [-0.1008,  0.0075],\n",
      "        [-0.0070, -0.1589],\n",
      "        [-0.1785, -0.1596],\n",
      "        [-0.2255,  0.0586],\n",
      "        [ 0.0304,  0.1414],\n",
      "        [-0.1340, -0.0861],\n",
      "        [-0.1360, -0.1145],\n",
      "        [ 0.0023, -0.0488],\n",
      "        [ 0.0208,  0.0165],\n",
      "        [-0.0395, -0.2010],\n",
      "        [-0.1105, -0.3149],\n",
      "        [ 0.5527, -0.2332],\n",
      "        [ 0.0371,  0.0687],\n",
      "        [-0.5000, -0.1857],\n",
      "        [ 0.0671, -0.2543],\n",
      "        [ 0.0506,  0.1294],\n",
      "        [-0.0721,  0.1994],\n",
      "        [ 0.1344,  0.2471],\n",
      "        [-0.2417,  0.0888],\n",
      "        [ 0.6305, -0.0510],\n",
      "        [ 0.1426,  0.1018],\n",
      "        [-0.2991,  0.1455],\n",
      "        [ 0.0521,  0.3869],\n",
      "        [-0.0139, -0.0182],\n",
      "        [ 0.1056,  0.2756],\n",
      "        [-0.0190,  0.0372],\n",
      "        [-0.3259, -0.1181],\n",
      "        [ 0.1574,  0.1612],\n",
      "        [-0.2477,  0.4355],\n",
      "        [-0.2461, -0.0514],\n",
      "        [ 0.2829,  0.3684],\n",
      "        [ 0.3125, -0.1091],\n",
      "        [ 0.1215,  0.1129],\n",
      "        [-0.0959, -0.0441],\n",
      "        [ 0.2493, -0.2300],\n",
      "        [-0.1546,  0.0461],\n",
      "        [ 0.0644,  0.0712],\n",
      "        [ 0.8732,  0.6578],\n",
      "        [-0.0216,  0.3256],\n",
      "        [ 0.1444,  0.1423],\n",
      "        [ 0.1911, -0.0209],\n",
      "        [ 0.0370,  0.4109]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 6: [250|250], class loss:0.2508198618888855, class accuracy: 94.15, domain loss: 0.6863307952880859, domain accuracy: 51.23125\n",
      "Testing epoch, class loss:0.4232567804865539,  class accuracy: 85.6, mAP: 0.8501556567849217, domain loss: 0.6903848722577095, domain accuracy: 54.55\n",
      "\n",
      "Training epoch 7: [250|250], class loss:0.2252047061920166, class accuracy: 97.225, domain loss: 0.6601918935775757, domain accuracy: 55.825\n",
      "Testing epoch, class loss:0.4235530784353614,  class accuracy: 85.75, mAP: 0.8497928052240807, domain loss: 0.6832386516034603, domain accuracy: 60.5\n",
      "\n",
      "Training epoch 8: [250|250], class loss:0.22408923506736755, class accuracy: 97.26875, domain loss: 0.681687593460083, domain accuracy: 55.85625\n",
      "Testing epoch, class loss:0.4235530784353614,  class accuracy: 85.75, mAP: 0.8497928052240807, domain loss: 0.6816285941749811, domain accuracy: 60.85\n",
      "\n",
      "learning rate: 1e-06\n",
      "epoch number: 12\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([-3.6639,  6.8493, -6.2267, -5.4227, -3.0034,  4.3067, -4.2081, -5.1838,\n",
      "        -3.6821, -6.3964,  1.4970, -8.6422, -3.8667, -4.3756,  4.3924, -5.6047,\n",
      "         4.1661, -6.2308, -3.6246, -4.7321, -0.1774, -5.8570, -6.4551,  7.5704,\n",
      "        -4.6258, -1.9615, -6.1400,  4.5413,  2.6095,  4.3762, -2.0583, -4.3306,\n",
      "        -6.6889,  6.5475, -4.6748, -5.6382,  4.1918,  0.0277, -6.7680, -2.7297,\n",
      "        -4.1282,  7.7492, -5.5203, -4.2238, -2.4840, -5.6099, -5.2823,  2.7001,\n",
      "        -0.2327, -0.9699, -4.8434, -6.2531, -5.5922,  3.3992, -5.0930, -3.2880,\n",
      "         3.3848, -4.4929,  1.8208,  6.0716, -3.8055, -3.3679,  4.6966, -3.2980],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.1881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[-7.2271e-02, -9.0572e-02],\n",
      "        [ 4.9874e-01,  4.1047e-02],\n",
      "        [ 2.8686e-03,  3.8168e-01],\n",
      "        [ 3.0987e-01,  5.0155e-01],\n",
      "        [-2.4216e-02,  1.1255e-01],\n",
      "        [-7.8987e-02, -9.8984e-02],\n",
      "        [ 3.2298e-01,  3.7502e-01],\n",
      "        [ 8.9467e-02,  2.0709e-01],\n",
      "        [-7.7513e-02,  3.8232e-02],\n",
      "        [ 1.0542e-01,  4.7752e-01],\n",
      "        [ 2.0910e-01, -2.3315e-02],\n",
      "        [ 3.0345e-02,  1.7635e-01],\n",
      "        [-1.7162e-02,  5.7156e-02],\n",
      "        [ 5.0939e-01,  5.1321e-01],\n",
      "        [ 2.9436e-01,  7.4647e-02],\n",
      "        [-4.2096e-01, -2.3439e-01],\n",
      "        [-2.8880e-02, -3.3199e-01],\n",
      "        [ 1.5702e-01,  1.5168e-01],\n",
      "        [-1.4439e-01,  1.4575e-01],\n",
      "        [-3.4710e-02,  6.6149e-02],\n",
      "        [-6.5839e-02, -1.0039e-01],\n",
      "        [ 1.5504e-01,  1.3508e-01],\n",
      "        [ 3.9681e-01,  4.6745e-01],\n",
      "        [ 8.4298e-01, -2.5294e-01],\n",
      "        [ 9.1201e-04,  5.3910e-01],\n",
      "        [ 1.1403e-01,  6.4221e-02],\n",
      "        [-5.5425e-01, -1.0160e-01],\n",
      "        [-1.8669e-01, -3.5319e-02],\n",
      "        [ 1.8764e-02,  3.1316e-04],\n",
      "        [ 3.1725e-01,  8.5871e-02],\n",
      "        [-1.2453e-01, -7.5457e-02],\n",
      "        [ 3.5933e-01,  4.6950e-01],\n",
      "        [-2.7178e-01,  1.5724e-01],\n",
      "        [ 2.6722e-01, -6.1069e-02],\n",
      "        [-4.6694e-02,  1.2577e-01],\n",
      "        [-3.4937e-01,  8.1853e-02],\n",
      "        [ 2.3428e-01, -4.7223e-01],\n",
      "        [-2.2300e-02,  7.1915e-02],\n",
      "        [-1.8413e-01,  5.6884e-02],\n",
      "        [ 1.4838e-01,  1.9794e-01],\n",
      "        [ 2.6065e-01,  5.1514e-01],\n",
      "        [ 4.0393e-01, -4.0224e-01],\n",
      "        [ 9.5260e-02,  2.7289e-02],\n",
      "        [ 6.8634e-02,  3.6748e-01],\n",
      "        [ 2.0817e-02,  1.8185e-01],\n",
      "        [ 3.2180e-01,  3.2029e-01],\n",
      "        [ 3.8885e-02,  1.3197e-01],\n",
      "        [-7.7005e-02, -2.4469e-01],\n",
      "        [-5.7195e-02, -1.0175e-01],\n",
      "        [-2.8368e-02, -4.7385e-02],\n",
      "        [-1.0191e-01,  2.3941e-01],\n",
      "        [-1.0364e-01,  2.0050e-01],\n",
      "        [-9.7353e-02,  1.3555e-01],\n",
      "        [ 3.8924e-01,  1.2099e-01],\n",
      "        [-1.6528e-01,  1.7702e-01],\n",
      "        [ 1.3055e-02,  9.9192e-02],\n",
      "        [-1.1512e-01, -3.6355e-02],\n",
      "        [ 2.5859e-02,  1.1152e-01],\n",
      "        [ 7.9675e-02,  8.0825e-02],\n",
      "        [ 2.1755e-01, -3.6125e-01],\n",
      "        [-7.8044e-02,  6.1911e-02],\n",
      "        [ 7.8159e-02,  3.7255e-01],\n",
      "        [ 2.0088e-01, -2.9201e-01],\n",
      "        [ 2.8961e-01,  5.4658e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 9: [250|250], class loss:0.2449837327003479, class accuracy: 97.475, domain loss: 0.689383864402771, domain accuracy: 51.00625\n",
      "Testing epoch, class loss:0.42652561655268073,  class accuracy: 85.9, mAP: 0.8475858469944478, domain loss: 0.688897019252181, domain accuracy: 57.6\n",
      "\n",
      "Training epoch 10: [250|250], class loss:0.2453252673149109, class accuracy: 97.8, domain loss: 0.6782185435295105, domain accuracy: 56.1\n",
      "Testing epoch, class loss:0.4272738043218851,  class accuracy: 85.9, mAP: 0.8475796693655314, domain loss: 0.6825568303465843, domain accuracy: 60.7\n",
      "\n",
      "Training epoch 11: [250|250], class loss:0.24402624368667603, class accuracy: 97.76875, domain loss: 0.6618314981460571, domain accuracy: 56.93125\n",
      "Testing epoch, class loss:0.4272738043218851,  class accuracy: 85.9, mAP: 0.8475796693655314, domain loss: 0.6821743678301573, domain accuracy: 60.35\n",
      "\n",
      "Training epoch 12: [250|250], class loss:0.2089378535747528, class accuracy: 97.86875, domain loss: 0.6874462366104126, domain accuracy: 51.59375\n",
      "Testing epoch, class loss:0.4359060055576265,  class accuracy: 85.85, mAP: 0.8448944280242182, domain loss: 0.6890700086951256, domain accuracy: 58.65\n",
      "\n",
      "Training epoch 13: [250|250], class loss:0.21095041930675507, class accuracy: 98.225, domain loss: 0.6707982420921326, domain accuracy: 55.9625\n",
      "Testing epoch, class loss:0.43653486762195826,  class accuracy: 85.95, mAP: 0.8452309346823225, domain loss: 0.6827213130891323, domain accuracy: 61.35\n",
      "\n",
      "Training epoch 14: [250|250], class loss:0.21243421733379364, class accuracy: 98.21875, domain loss: 0.6684319376945496, domain accuracy: 57.48125\n",
      "Testing epoch, class loss:0.43653486762195826,  class accuracy: 85.95, mAP: 0.8452309346823225, domain loss: 0.6823758911341429, domain accuracy: 60.9\n",
      "\n",
      "Training epoch 15: [250|250], class loss:0.19338621199131012, class accuracy: 98.29375, domain loss: 0.7018110752105713, domain accuracy: 52.08125\n",
      "Testing epoch, class loss:0.44686154881492257,  class accuracy: 86.0, mAP: 0.8420461738105764, domain loss: 0.6890644375234842, domain accuracy: 58.95\n",
      "\n",
      "Training epoch 16: [250|250], class loss:0.19280466437339783, class accuracy: 98.59375, domain loss: 0.6822407245635986, domain accuracy: 56.075\n",
      "Testing epoch, class loss:0.44744754768908024,  class accuracy: 85.95, mAP: 0.842071263177881, domain loss: 0.6830112133175135, domain accuracy: 61.2\n",
      "\n",
      "Training epoch 17: [250|250], class loss:0.18579429388046265, class accuracy: 98.5, domain loss: 0.682809054851532, domain accuracy: 57.625\n",
      "Testing epoch, class loss:0.44744754768908024,  class accuracy: 85.95, mAP: 0.842071263177881, domain loss: 0.6827101316303015, domain accuracy: 61.2\n",
      "\n",
      "Training epoch 18: [250|250], class loss:0.16203437745571136, class accuracy: 98.59375, domain loss: 0.7108372449874878, domain accuracy: 51.99375\n",
      "Testing epoch, class loss:0.4590780180878937,  class accuracy: 86.0, mAP: 0.8387839908080353, domain loss: 0.68915637396276, domain accuracy: 60.7\n",
      "\n",
      "Training epoch 19: [250|250], class loss:0.15532293915748596, class accuracy: 98.8625, domain loss: 0.6729748845100403, domain accuracy: 55.9125\n",
      "Testing epoch, class loss:0.45972800021991134,  class accuracy: 86.0, mAP: 0.8387860930331732, domain loss: 0.6828196011483669, domain accuracy: 60.95\n",
      "\n",
      "Training epoch 20: [250|250], class loss:0.14997746050357819, class accuracy: 98.8875, domain loss: 0.6585413217544556, domain accuracy: 57.5375\n",
      "Testing epoch, class loss:0.45972800021991134,  class accuracy: 86.0, mAP: 0.8387860930331732, domain loss: 0.6825358085334301, domain accuracy: 60.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish training epoch 21, dev class loss: 0.45972800021991134, dev doamin loss: 0.6825358085334301, dev mAP: 0.8387860930331732,domain_accuracy: 60.95, time used: 0:51:28.317845\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "   model_random_state  test_accuracy  test_gender_accuracy  \\\n",
      "0                   1         0.8450                0.5985   \n",
      "1                   2         0.8565                0.6160   \n",
      "2                   3         0.8630                0.6045   \n",
      "3                   4         0.8575                0.6100   \n",
      "\n",
      "   test_male_true_proportion  test_female_true_proportion  \\\n",
      "0                   0.302895                     0.398162   \n",
      "1                   0.319911                     0.409712   \n",
      "2                   0.295570                     0.356340   \n",
      "3                   0.288262                     0.397554   \n",
      "\n",
      "   test_male_predicted_proportion  test_female_predicted_proportion  \\\n",
      "0                        0.290275                          0.381317   \n",
      "1                        0.275913                          0.379363   \n",
      "2                        0.286129                          0.367576   \n",
      "3                        0.282318                          0.408257   \n",
      "\n",
      "   test_male_average_score  test_female_average_score  \\\n",
      "0                 0.297638                   0.378439   \n",
      "1                 0.280973                   0.386162   \n",
      "2                 0.286778                   0.365670   \n",
      "3                 0.295156                   0.413692   \n",
      "\n",
      "   balanced_chicago_accuracy  ...  \\\n",
      "0                   0.960924  ...   \n",
      "1                   0.914742  ...   \n",
      "2                   0.928952  ...   \n",
      "3                   0.960924  ...   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion  \\\n",
      "0                                      0.342037   \n",
      "1                                      0.344648   \n",
      "2                                      0.334204   \n",
      "3                                      0.339426   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion  selected_2_chicago_bias  \\\n",
      "0                                        0.383812                 0.041775   \n",
      "1                                        0.381201                 0.036554   \n",
      "2                                        0.391645                 0.057441   \n",
      "3                                        0.386423                 0.046997   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion_raw  \\\n",
      "0                                          0.261097   \n",
      "1                                          0.107050   \n",
      "2                                          0.080940   \n",
      "3                                          0.308094   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion_raw  \\\n",
      "0                                           0.313316    \n",
      "1                                           0.164491    \n",
      "2                                           0.177546    \n",
      "3                                           0.349869    \n",
      "\n",
      "   selected_2_chicago_bias_raw  selected_2_chicago_male_score  \\\n",
      "0                     0.052219                       0.253493   \n",
      "1                     0.057441                       0.118771   \n",
      "2                     0.096606                       0.096812   \n",
      "3                     0.041775                       0.319056   \n",
      "\n",
      "   selected_2_chicago_female_score  \\\n",
      "0                         0.297996   \n",
      "1                         0.167062   \n",
      "2                         0.175278   \n",
      "3                         0.367595   \n",
      "\n",
      "   selected_2_chicago_male_score_neutral_faces  \\\n",
      "0                                     0.002771   \n",
      "1                                     0.009771   \n",
      "2                                     0.002173   \n",
      "3                                     0.035394   \n",
      "\n",
      "   selected_2_chicago_female_score_neutral_faces  \n",
      "0                                       0.011685  \n",
      "1                                       0.008950  \n",
      "2                                       0.005565  \n",
      "3                                       0.075629  \n",
      "\n",
      "[4 rows x 54 columns]\n",
      "16000 train faces, 2000 validation faces, 2000 test faces\n",
      "\n",
      "learning rate: 0.0001\n",
      "epoch number: 3\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 0.2182,  0.0497, -0.0580, -0.0747, -0.0439, -0.0263, -0.1157, -0.1544,\n",
      "        -0.2010,  0.3000,  0.0051, -0.1248,  0.1011, -0.1142, -0.0846,  0.0875,\n",
      "        -0.0006, -0.0866,  0.0252, -0.3663,  0.1015, -0.2328, -0.0099,  0.1845,\n",
      "        -0.1667,  0.0748,  0.1723,  0.1325, -0.1355, -0.2184, -0.2130, -0.3923,\n",
      "         0.2061, -0.4061, -0.0552, -0.1793,  0.0303, -0.2425, -0.0239, -0.1564,\n",
      "        -0.2089, -0.0478,  0.0143,  0.2019,  0.0060,  0.0474, -0.1082, -0.0854,\n",
      "        -0.3146,  0.0174, -0.0967,  0.2436, -0.3397, -0.1080,  0.1407, -0.1829,\n",
      "        -0.0847, -0.1566, -0.2770, -0.1476, -0.0014,  0.0264,  0.0199,  0.2506],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 1.1971e-02,  1.3026e-01],\n",
      "        [-2.9727e-02, -2.8287e-02],\n",
      "        [ 9.6534e-02,  2.2437e-01],\n",
      "        [-3.3139e-02, -4.2098e-02],\n",
      "        [ 3.0690e-01, -4.3395e-02],\n",
      "        [-1.0488e-01, -2.0889e-01],\n",
      "        [ 5.6146e-02,  1.0352e-01],\n",
      "        [-1.9205e-01,  3.1920e-02],\n",
      "        [ 7.5575e-02,  1.6150e-01],\n",
      "        [ 1.9297e-02, -1.1675e-01],\n",
      "        [ 2.7911e-02,  1.3008e-01],\n",
      "        [-2.3449e-01,  1.2579e-01],\n",
      "        [-2.9953e-01,  8.0575e-02],\n",
      "        [-1.5422e-02,  4.5611e-02],\n",
      "        [-9.5135e-02,  1.8928e-01],\n",
      "        [-2.2879e-02,  3.2984e-01],\n",
      "        [ 1.2385e-01,  1.1639e-01],\n",
      "        [ 7.7503e-03, -1.0667e-01],\n",
      "        [ 3.3237e-01,  3.9617e-01],\n",
      "        [ 5.7074e-02, -1.4512e-01],\n",
      "        [ 7.9902e-02,  1.9363e-01],\n",
      "        [ 4.4399e-02,  3.9511e-01],\n",
      "        [ 1.6300e-01,  1.8193e-01],\n",
      "        [-8.8792e-02,  2.0313e-01],\n",
      "        [-9.2933e-03,  6.2595e-02],\n",
      "        [-2.3300e-01, -2.7665e-03],\n",
      "        [-7.0928e-02,  2.1500e-01],\n",
      "        [-5.5196e-02,  2.1904e-01],\n",
      "        [-1.6006e-01, -2.1506e-02],\n",
      "        [-1.5768e-01, -8.9599e-02],\n",
      "        [-6.4224e-02,  1.4838e-01],\n",
      "        [ 2.6843e-01,  8.3960e-02],\n",
      "        [-6.2821e-02, -1.7978e-01],\n",
      "        [-9.0524e-02,  3.1635e-02],\n",
      "        [ 1.4825e-01, -5.6671e-02],\n",
      "        [-6.9511e-02, -1.4779e-01],\n",
      "        [-4.4581e-02, -1.5307e-01],\n",
      "        [-8.6635e-02, -1.6082e-01],\n",
      "        [-9.1626e-02,  1.3418e-01],\n",
      "        [ 1.2456e-01, -2.3029e-01],\n",
      "        [-1.4336e-01, -2.2180e-01],\n",
      "        [ 7.4669e-05,  8.9546e-02],\n",
      "        [ 9.6613e-02, -2.0764e-01],\n",
      "        [-2.9621e-02,  6.8237e-02],\n",
      "        [ 3.9366e-02, -8.1271e-02],\n",
      "        [-1.1122e-01, -1.3992e-01],\n",
      "        [ 1.7565e-01, -1.4740e-01],\n",
      "        [ 3.4154e-01, -9.8851e-02],\n",
      "        [-1.5826e-01,  2.9899e-01],\n",
      "        [-1.6488e-01,  7.1490e-02],\n",
      "        [ 8.6620e-02,  1.2629e-01],\n",
      "        [-2.1417e-01,  2.1953e-01],\n",
      "        [-8.3486e-02,  3.1283e-01],\n",
      "        [-1.7106e-01,  2.1701e-01],\n",
      "        [ 1.4659e-02, -1.6155e-02],\n",
      "        [ 1.1234e-01,  3.1562e-02],\n",
      "        [ 8.3363e-02,  3.5589e-01],\n",
      "        [ 2.3070e-03, -1.8022e-01],\n",
      "        [-2.2518e-01, -9.6201e-02],\n",
      "        [-1.7128e-01,  9.6805e-02],\n",
      "        [ 1.3588e-01,  1.0622e-01],\n",
      "        [-1.1506e-01,  1.8154e-01],\n",
      "        [-5.2328e-02, -2.4800e-01],\n",
      "        [ 2.2989e-01, -9.5187e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.7165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 0: [250|250], class loss:0.3378368616104126, class accuracy: 80.94375, domain loss: 0.6806023120880127, domain accuracy: 49.7375\n",
      "Testing epoch, class loss:0.33987257862463593,  class accuracy: 86.15, mAP: 0.8654604773478013, domain loss: 0.6911566741764545, domain accuracy: 54.55\n",
      "\n",
      "Training epoch 1: [250|250], class loss:0.29983407258987427, class accuracy: 89.6, domain loss: 0.7538084387779236, domain accuracy: 57.35625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch, class loss:0.3373802420683205,  class accuracy: 86.4, mAP: 0.8662239720908407, domain loss: 0.6933228150010109, domain accuracy: 65.45\n",
      "\n",
      "Training epoch 2: [250|250], class loss:0.29517242312431335, class accuracy: 89.6625, domain loss: 0.7386156320571899, domain accuracy: 58.06875\n",
      "Testing epoch, class loss:0.3373802420683205,  class accuracy: 86.4, mAP: 0.8662239720908407, domain loss: 0.6905671637505293, domain accuracy: 66.35\n",
      "\n",
      "learning rate: 1e-05\n",
      "epoch number: 6\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 0.3555, -3.4150, -0.6483, -3.1381, -2.9582, -3.2947, -1.2859, -0.7418,\n",
      "        -3.6357, -1.4021,  2.8323,  2.8841, -2.0362, -1.9189, -0.2052, -0.7702,\n",
      "        -1.7162, -0.7009, -1.0768, -1.7658,  1.6557, -0.9076, -0.0438,  0.1942,\n",
      "         3.5960, -0.7873,  3.9240, -1.3705, -2.3158,  5.3328, -3.7716, -2.5562,\n",
      "        -4.9491, -2.2194,  3.4727, -3.8697, -0.5664,  4.0815, -3.6598,  2.9857,\n",
      "        -1.5657, -1.1151, -2.1858, -4.0707, -4.6547, -0.1145, -1.1701, -0.5500,\n",
      "         3.9589, -2.6120, -2.5942, -2.6460, -1.3756,  2.7914, -1.9098,  0.9311,\n",
      "        -2.0684,  4.0110, -1.9127, -0.2568, -1.4482, -2.3091, -3.4800, -3.2483],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.3769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 0.0916,  0.1759],\n",
      "        [-0.4437,  0.1905],\n",
      "        [-0.1636,  0.1860],\n",
      "        [-0.3608,  0.4147],\n",
      "        [ 0.1040,  0.4157],\n",
      "        [-0.0538,  0.4517],\n",
      "        [-0.0329,  0.2990],\n",
      "        [-0.0622,  0.1987],\n",
      "        [-0.1716,  0.9872],\n",
      "        [ 0.0168,  0.4918],\n",
      "        [ 0.2209, -0.0715],\n",
      "        [-0.2239,  0.1572],\n",
      "        [-0.0168,  0.4911],\n",
      "        [-0.3229,  0.2686],\n",
      "        [ 0.0553,  0.1896],\n",
      "        [ 0.0049,  0.1677],\n",
      "        [-0.1748,  0.5386],\n",
      "        [ 0.0782,  0.0600],\n",
      "        [ 0.0609,  0.3024],\n",
      "        [-0.1697,  0.4027],\n",
      "        [ 0.1481, -0.0728],\n",
      "        [-0.0702,  0.4392],\n",
      "        [ 0.1357,  0.0797],\n",
      "        [ 0.1204,  0.2291],\n",
      "        [ 0.5512,  0.4057],\n",
      "        [-0.0793,  0.2989],\n",
      "        [-0.0095, -0.4964],\n",
      "        [-0.1202,  0.2824],\n",
      "        [-0.0953,  0.7943],\n",
      "        [-0.1685, -0.8748],\n",
      "        [-0.4668, -0.2394],\n",
      "        [-0.0084,  0.7638],\n",
      "        [-0.5615,  1.1052],\n",
      "        [ 0.2500,  0.6267],\n",
      "        [ 0.3937, -0.8065],\n",
      "        [-0.4790,  0.7139],\n",
      "        [ 0.0398,  0.2727],\n",
      "        [ 0.5305, -0.5471],\n",
      "        [-0.3880,  0.5251],\n",
      "        [ 0.1143, -0.0543],\n",
      "        [-0.2509,  0.2303],\n",
      "        [-0.3039,  0.4892],\n",
      "        [-0.0163,  0.8788],\n",
      "        [ 0.1901,  0.9453],\n",
      "        [-0.2309,  0.3564],\n",
      "        [-0.0113,  0.0402],\n",
      "        [ 0.1828,  0.2776],\n",
      "        [-0.1094,  0.2022],\n",
      "        [ 0.4932,  0.0667],\n",
      "        [-0.5146,  0.4047],\n",
      "        [-0.1773,  0.8540],\n",
      "        [-0.3664,  0.5308],\n",
      "        [ 0.1706,  0.4791],\n",
      "        [-0.0138,  0.1804],\n",
      "        [-0.1972,  0.3043],\n",
      "        [-0.0050,  0.0910],\n",
      "        [ 0.3676,  0.5462],\n",
      "        [ 0.2484, -0.2168],\n",
      "        [-0.2628,  0.3816],\n",
      "        [-0.1528,  0.1815],\n",
      "        [-0.1228,  0.3180],\n",
      "        [-0.4667,  0.3417],\n",
      "        [-0.1612,  0.7384],\n",
      "        [-0.2838,  0.3482]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 3: [250|250], class loss:0.3014725148677826, class accuracy: 90.6375, domain loss: 0.6795178651809692, domain accuracy: 52.44375\n",
      "Testing epoch, class loss:0.36470168083906174,  class accuracy: 86.95, mAP: 0.8649765116549165, domain loss: 0.6884204745292664, domain accuracy: 59.5\n",
      "\n",
      "Training epoch 4: [250|250], class loss:0.27712881565093994, class accuracy: 94.11875, domain loss: 0.726479172706604, domain accuracy: 54.775\n",
      "Testing epoch, class loss:0.3556706318631768,  class accuracy: 86.6, mAP: 0.865124695325265, domain loss: 0.6818778719753027, domain accuracy: 61.4\n",
      "\n",
      "Training epoch 5: [250|250], class loss:0.2855621576309204, class accuracy: 94.16875, domain loss: 0.7117406129837036, domain accuracy: 55.58125\n",
      "Testing epoch, class loss:0.3556706318631768,  class accuracy: 86.6, mAP: 0.865124695325265, domain loss: 0.6815591249614954, domain accuracy: 62.25\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 0.8968, -4.5442, -1.2352, -4.7930, -3.8139, -6.2217, -2.2573, -0.4049,\n",
      "        -4.8281, -1.6035,  3.8644,  3.9604, -3.4228, -2.3977,  0.4449, -2.0671,\n",
      "        -4.3420,  1.2861, -2.1219, -3.1166,  3.7109, -2.0418,  1.7244,  3.5690,\n",
      "         3.6791, -2.8921,  4.9964, -2.1701, -4.1505,  6.2981, -4.5819, -1.0798,\n",
      "        -6.0096, -3.4156,  3.2500, -5.9631, -0.7689,  5.1367, -5.0727,  3.2386,\n",
      "        -5.0480, -2.3911, -2.3706, -7.1186, -5.0126, -2.5208, -3.0532, -0.6633,\n",
      "         4.5558, -3.9147, -4.7496, -2.4867, -5.3438,  5.5943, -3.3191,  2.9448,\n",
      "        -4.5920,  4.8469, -3.8358, -1.1711, -2.7176, -5.4263, -4.7949, -4.6568],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.2468, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 0.0872,  0.1673],\n",
      "        [ 0.2602,  0.1747],\n",
      "        [-0.1765, -0.0656],\n",
      "        [-0.1025,  0.2745],\n",
      "        [ 0.0428,  0.2479],\n",
      "        [ 0.3454,  0.4095],\n",
      "        [-0.0362,  0.2158],\n",
      "        [ 0.0034,  0.0599],\n",
      "        [ 0.1328,  0.5342],\n",
      "        [-0.1484,  0.1970],\n",
      "        [-0.0918, -0.3224],\n",
      "        [ 0.0528, -0.0792],\n",
      "        [-0.1941,  0.3456],\n",
      "        [ 0.3298,  0.2967],\n",
      "        [ 0.0887, -0.1143],\n",
      "        [ 0.2479,  0.3364],\n",
      "        [ 0.1398,  0.4627],\n",
      "        [ 0.2049,  0.0011],\n",
      "        [ 0.1538,  0.2361],\n",
      "        [ 0.2012,  0.4756],\n",
      "        [ 0.5180,  0.2533],\n",
      "        [-0.0213,  0.3190],\n",
      "        [ 0.2855,  0.0761],\n",
      "        [ 0.2832,  0.0479],\n",
      "        [ 0.2545,  0.1695],\n",
      "        [-0.2688,  0.1465],\n",
      "        [ 0.4664, -0.1602],\n",
      "        [ 0.0420, -0.0207],\n",
      "        [ 0.3353,  0.0054],\n",
      "        [ 0.0104, -0.4773],\n",
      "        [-0.0850, -0.0432],\n",
      "        [ 0.1047,  0.2637],\n",
      "        [ 0.0405,  0.5621],\n",
      "        [ 0.2668,  0.4242],\n",
      "        [ 0.4551,  0.1353],\n",
      "        [ 0.0948,  0.5538],\n",
      "        [-0.0157,  0.2517],\n",
      "        [ 0.1642, -0.3706],\n",
      "        [ 0.0960,  0.4732],\n",
      "        [ 0.2654,  0.2433],\n",
      "        [ 0.1211,  0.2972],\n",
      "        [ 0.0931,  0.3295],\n",
      "        [ 0.0518, -0.0784],\n",
      "        [ 0.7005,  0.7381],\n",
      "        [ 0.2060,  0.5167],\n",
      "        [ 0.2999,  0.4581],\n",
      "        [-0.0305,  0.3185],\n",
      "        [ 0.0926,  0.2991],\n",
      "        [ 0.0086, -0.1810],\n",
      "        [ 0.0684,  0.3554],\n",
      "        [ 0.1331,  0.2614],\n",
      "        [ 0.2798,  0.3573],\n",
      "        [ 0.3077,  0.7577],\n",
      "        [-0.0104,  0.0376],\n",
      "        [-0.0231,  0.1747],\n",
      "        [-0.0600, -0.1776],\n",
      "        [ 0.0453,  0.3326],\n",
      "        [ 0.1481,  0.2181],\n",
      "        [-0.3788,  0.0228],\n",
      "        [ 0.1030,  0.3110],\n",
      "        [ 0.0309,  0.2769],\n",
      "        [ 0.3941,  0.9582],\n",
      "        [ 0.2494,  0.8353],\n",
      "        [-0.1660,  0.4370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 6: [250|250], class loss:0.1652790606021881, class accuracy: 94.45, domain loss: 0.6880379319190979, domain accuracy: 51.6125\n",
      "Testing epoch, class loss:0.44070960441604257,  class accuracy: 86.6, mAP: 0.8503611810064159, domain loss: 0.6908583324402571, domain accuracy: 61.55\n",
      "\n",
      "Training epoch 7: [250|250], class loss:0.14598098397254944, class accuracy: 97.60625, domain loss: 0.7233008742332458, domain accuracy: 54.9875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch, class loss:0.4314512889832258,  class accuracy: 85.85, mAP: 0.8505639861440855, domain loss: 0.6849650628864765, domain accuracy: 60.15\n",
      "\n",
      "Training epoch 8: [250|250], class loss:0.14186108112335205, class accuracy: 97.5875, domain loss: 0.7089899778366089, domain accuracy: 55.98125\n",
      "Testing epoch, class loss:0.4314512889832258,  class accuracy: 85.85, mAP: 0.8505639861440855, domain loss: 0.684381976723671, domain accuracy: 60.55\n",
      "\n",
      "learning rate: 1e-06\n",
      "epoch number: 12\n",
      "\n",
      "\n",
      "class outputs:\n",
      "tensor([ 2.3397, -5.0255, -5.3930, -4.9522, -5.5832, -5.4035, -2.9333,  3.7925,\n",
      "        -6.0555, -1.1613,  4.5215,  4.1061, -4.6925, -2.8906, -2.5909, -3.9152,\n",
      "        -6.0024,  3.4787, -4.2688, -4.0133,  4.9800, -3.5128,  3.6225,  4.8444,\n",
      "         3.5241, -5.2821,  5.3360, -2.9603, -3.8899,  6.7302, -5.6956,  1.0060,\n",
      "        -8.3084, -4.0222,  3.6554, -5.9203,  1.4218,  4.7647, -5.2669,  3.6459,\n",
      "        -8.4148, -4.9724, -2.5287, -7.1084, -6.1893, -5.0786, -3.9623, -0.2826,\n",
      "         5.7430, -3.8020, -4.4836,  0.2521, -6.9008,  6.2976, -4.9386,  4.6674,\n",
      "        -6.1245,  5.0023, -4.5177, -1.9903, -3.3269, -6.7583, -6.3073, -5.6531],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "class predicted\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "class loss\n",
      "tensor(0.1202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "\n",
      "domain outputs:\n",
      "tensor([[ 0.0628, -0.0129],\n",
      "        [ 0.1364,  0.5991],\n",
      "        [-0.0085,  0.5039],\n",
      "        [ 0.0909,  0.5070],\n",
      "        [-0.3184,  0.2121],\n",
      "        [ 0.2152,  0.2272],\n",
      "        [ 0.0536,  0.3216],\n",
      "        [-0.0255, -0.1539],\n",
      "        [-0.5799, -0.3190],\n",
      "        [-0.0402,  0.0506],\n",
      "        [ 0.1967, -0.3432],\n",
      "        [-0.0846, -0.3402],\n",
      "        [-0.1638,  0.2162],\n",
      "        [ 0.2972,  0.4575],\n",
      "        [ 0.1287,  0.2043],\n",
      "        [ 0.1624,  0.7585],\n",
      "        [ 0.8084,  0.7427],\n",
      "        [ 0.1337, -0.0377],\n",
      "        [ 0.1203,  0.6752],\n",
      "        [ 0.0948,  0.1268],\n",
      "        [ 0.2499, -0.0781],\n",
      "        [ 0.1910,  0.5083],\n",
      "        [ 0.0759, -0.2086],\n",
      "        [ 0.2274, -0.2459],\n",
      "        [ 0.3322,  0.1197],\n",
      "        [-0.1242,  0.5186],\n",
      "        [ 0.0285, -0.2929],\n",
      "        [-0.1245, -0.0355],\n",
      "        [ 0.1609,  0.2438],\n",
      "        [ 0.0846, -0.2520],\n",
      "        [-0.3708,  0.1109],\n",
      "        [ 0.1690,  0.0929],\n",
      "        [ 0.5705,  0.5690],\n",
      "        [ 0.0152,  0.0743],\n",
      "        [ 0.2864,  0.1223],\n",
      "        [ 0.1692,  0.3636],\n",
      "        [ 0.1105, -0.0138],\n",
      "        [ 0.2062, -0.2558],\n",
      "        [ 0.4029,  0.7954],\n",
      "        [ 0.0866, -0.0110],\n",
      "        [ 0.0577,  0.0555],\n",
      "        [ 0.1035,  0.6563],\n",
      "        [ 0.1223,  0.2137],\n",
      "        [ 0.1700,  0.3757],\n",
      "        [ 0.4048,  0.6274],\n",
      "        [ 0.2789,  0.4315],\n",
      "        [ 0.0842,  0.4309],\n",
      "        [ 0.1554,  0.1400],\n",
      "        [ 0.3147,  0.2398],\n",
      "        [-0.2949, -0.0867],\n",
      "        [ 0.0768,  0.4295],\n",
      "        [ 0.0437,  0.0835],\n",
      "        [-0.3524,  0.0092],\n",
      "        [ 0.0334,  0.1591],\n",
      "        [-0.1863,  0.2627],\n",
      "        [ 0.4869,  0.1022],\n",
      "        [-0.2476, -0.1182],\n",
      "        [ 0.1080, -0.1552],\n",
      "        [-0.0696,  0.2422],\n",
      "        [ 0.0992,  0.3080],\n",
      "        [ 0.0816,  0.0581],\n",
      "        [-0.0383,  0.3656],\n",
      "        [ 0.2094,  0.6133],\n",
      "        [-0.2547, -0.0241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "domain predicted\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "domain loss\n",
      "tensor(0.6733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training epoch 9: [250|250], class loss:0.1434975266456604, class accuracy: 97.7375, domain loss: 0.7032610774040222, domain accuracy: 53.425\n",
      "Testing epoch, class loss:0.44324998185038567,  class accuracy: 86.4, mAP: 0.8475416203260453, domain loss: 0.6880739778280258, domain accuracy: 63.55\n",
      "\n",
      "Training epoch 10: [250|250], class loss:0.14404752850532532, class accuracy: 98.04375, domain loss: 0.6883508563041687, domain accuracy: 56.075\n",
      "Testing epoch, class loss:0.4439615532755852,  class accuracy: 86.4, mAP: 0.8475868633729083, domain loss: 0.6828452367335558, domain accuracy: 60.3\n",
      "\n",
      "Training epoch 11: [250|250], class loss:0.1393854171037674, class accuracy: 98.05, domain loss: 0.697239339351654, domain accuracy: 56.15\n",
      "Testing epoch, class loss:0.4439615532755852,  class accuracy: 86.4, mAP: 0.8475868633729083, domain loss: 0.6825565472245216, domain accuracy: 60.25\n",
      "\n",
      "Training epoch 12: [250|250], class loss:0.13550055027008057, class accuracy: 98.1375, domain loss: 0.6788005232810974, domain accuracy: 53.25625\n",
      "Testing epoch, class loss:0.45574810123071074,  class accuracy: 86.45, mAP: 0.8447671087475351, domain loss: 0.6888156849890947, domain accuracy: 62.15\n",
      "\n",
      "Training epoch 13: [250|250], class loss:0.12408564239740372, class accuracy: 98.50625, domain loss: 0.7035222053527832, domain accuracy: 56.0375\n",
      "Testing epoch, class loss:0.4561833217740059,  class accuracy: 86.4, mAP: 0.8447894871216755, domain loss: 0.6834479812532663, domain accuracy: 60.4\n",
      "\n",
      "Training epoch 14: [250|250], class loss:0.13412916660308838, class accuracy: 98.54375, domain loss: 0.6890015006065369, domain accuracy: 56.64375\n",
      "Testing epoch, class loss:0.4561833217740059,  class accuracy: 86.4, mAP: 0.8447894871216755, domain loss: 0.6831843089312315, domain accuracy: 60.45\n",
      "\n",
      "Training epoch 15: [250|250], class loss:0.12086858600378036, class accuracy: 98.6125, domain loss: 0.6838082075119019, domain accuracy: 52.20625\n",
      "Testing epoch, class loss:0.4689098196104169,  class accuracy: 86.3, mAP: 0.842637144646031, domain loss: 0.6885945424437523, domain accuracy: 63.1\n",
      "\n",
      "Training epoch 16: [250|250], class loss:0.11048410832881927, class accuracy: 98.78125, domain loss: 0.7164240479469299, domain accuracy: 55.53125\n",
      "Testing epoch, class loss:0.46934243850409985,  class accuracy: 86.25, mAP: 0.8426317740466668, domain loss: 0.683788338676095, domain accuracy: 60.4\n",
      "\n",
      "Training epoch 17: [250|250], class loss:0.1138879805803299, class accuracy: 98.85, domain loss: 0.6956982612609863, domain accuracy: 56.8\n",
      "Testing epoch, class loss:0.46934243850409985,  class accuracy: 86.25, mAP: 0.8426317740466668, domain loss: 0.6835493985563517, domain accuracy: 60.4\n",
      "\n",
      "Training epoch 18: [250|250], class loss:0.1026666909456253, class accuracy: 98.8125, domain loss: 0.6922297477722168, domain accuracy: 52.15625\n",
      "Testing epoch, class loss:0.4821269176900387,  class accuracy: 86.3, mAP: 0.8409422672309761, domain loss: 0.6886666174978018, domain accuracy: 57.45\n",
      "\n",
      "Training epoch 19: [250|250], class loss:0.11076349020004272, class accuracy: 99.05625, domain loss: 0.7055137753486633, domain accuracy: 55.0125\n",
      "Testing epoch, class loss:0.4826015289872885,  class accuracy: 86.2, mAP: 0.8409349622992313, domain loss: 0.6839895993471146, domain accuracy: 60.65\n",
      "\n",
      "Training epoch 20: [250|250], class loss:0.10587714612483978, class accuracy: 99.04375, domain loss: 0.713372528553009, domain accuracy: 56.48125\n",
      "Testing epoch, class loss:0.4826015289872885,  class accuracy: 86.2, mAP: 0.8409349622992313, domain loss: 0.6837829500436783, domain accuracy: 60.55\n",
      "Finish training epoch 21, dev class loss: 0.4826015289872885, dev doamin loss: 0.6837829500436783, dev mAP: 0.8409349622992313,domain_accuracy: 60.55, time used: 0:53:31.594749\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "   model_random_state  test_accuracy  test_gender_accuracy  \\\n",
      "0                   1         0.8450                0.5985   \n",
      "1                   2         0.8565                0.6160   \n",
      "2                   3         0.8630                0.6045   \n",
      "3                   4         0.8575                0.6100   \n",
      "4                   5         0.8605                0.6075   \n",
      "\n",
      "   test_male_true_proportion  test_female_true_proportion  \\\n",
      "0                   0.302895                     0.398162   \n",
      "1                   0.319911                     0.409712   \n",
      "2                   0.295570                     0.356340   \n",
      "3                   0.288262                     0.397554   \n",
      "4                   0.286138                     0.368664   \n",
      "\n",
      "   test_male_predicted_proportion  test_female_predicted_proportion  \\\n",
      "0                        0.290275                          0.381317   \n",
      "1                        0.275913                          0.379363   \n",
      "2                        0.286129                          0.367576   \n",
      "3                        0.282318                          0.408257   \n",
      "4                        0.274277                          0.367127   \n",
      "\n",
      "   test_male_average_score  test_female_average_score  \\\n",
      "0                 0.297638                   0.378439   \n",
      "1                 0.280973                   0.386162   \n",
      "2                 0.286778                   0.365670   \n",
      "3                 0.295156                   0.413692   \n",
      "4                 0.278083                   0.365868   \n",
      "\n",
      "   balanced_chicago_accuracy  ...  \\\n",
      "0                   0.960924  ...   \n",
      "1                   0.914742  ...   \n",
      "2                   0.928952  ...   \n",
      "3                   0.960924  ...   \n",
      "4                   0.946714  ...   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion  \\\n",
      "0                                      0.342037   \n",
      "1                                      0.344648   \n",
      "2                                      0.334204   \n",
      "3                                      0.339426   \n",
      "4                                      0.339426   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion  selected_2_chicago_bias  \\\n",
      "0                                        0.383812                 0.041775   \n",
      "1                                        0.381201                 0.036554   \n",
      "2                                        0.391645                 0.057441   \n",
      "3                                        0.386423                 0.046997   \n",
      "4                                        0.386423                 0.046997   \n",
      "\n",
      "   selected_2_chicago_male_predicted_proportion_raw  \\\n",
      "0                                          0.261097   \n",
      "1                                          0.107050   \n",
      "2                                          0.080940   \n",
      "3                                          0.308094   \n",
      "4                                          0.240209   \n",
      "\n",
      "   selected_2_chicago_female_predicted_proportion_raw  \\\n",
      "0                                           0.313316    \n",
      "1                                           0.164491    \n",
      "2                                           0.177546    \n",
      "3                                           0.349869    \n",
      "4                                           0.271540    \n",
      "\n",
      "   selected_2_chicago_bias_raw  selected_2_chicago_male_score  \\\n",
      "0                     0.052219                       0.253493   \n",
      "1                     0.057441                       0.118771   \n",
      "2                     0.096606                       0.096812   \n",
      "3                     0.041775                       0.319056   \n",
      "4                     0.031332                       0.233361   \n",
      "\n",
      "   selected_2_chicago_female_score  \\\n",
      "0                         0.297996   \n",
      "1                         0.167062   \n",
      "2                         0.175278   \n",
      "3                         0.367595   \n",
      "4                         0.265929   \n",
      "\n",
      "   selected_2_chicago_male_score_neutral_faces  \\\n",
      "0                                     0.002771   \n",
      "1                                     0.009771   \n",
      "2                                     0.002173   \n",
      "3                                     0.035394   \n",
      "4                                     0.012243   \n",
      "\n",
      "   selected_2_chicago_female_score_neutral_faces  \n",
      "0                                       0.011685  \n",
      "1                                       0.008950  \n",
      "2                                       0.005565  \n",
      "3                                       0.075629  \n",
      "4                                       0.015922  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,6):\n",
    "\n",
    "    # Split into train/validation/test sets\n",
    "    frame = frame_copy.sample(n = 20000, random_state = k).reset_index(drop=True) # shuffle data frame\n",
    "    n_images = len(frame)\n",
    "    n_train = int(0.8 * n_images)\n",
    "    n_val = int((n_images - n_train) / 2)\n",
    "    n_test = n_images - n_train - n_val\n",
    "\n",
    "    train_frame = frame[0 : n_train].reset_index(drop=True)\n",
    "    val_frame = frame[n_train : n_train + n_val].reset_index(drop=True)\n",
    "    test_frame = frame[n_train + n_val : ].reset_index(drop=True)\n",
    "\n",
    "    print(\"{} train faces, {} validation faces, {} test faces\".format(len(train_frame), len(val_frame), len(test_frame)))\n",
    "\n",
    "    # Data loaders and transforms for training\n",
    "\n",
    "    # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "    # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second\n",
    "    # image.\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "    # Define our sequence of augmentation steps that will be applied to every image.\n",
    "    class ImgAugTransform:\n",
    "\n",
    "        def __init__(self):\n",
    "            self.aug = iaa.Sequential(\n",
    "            [\n",
    "                #\n",
    "                # Apply the following augmenters to most images.\n",
    "                #\n",
    "                iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "                #iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "\n",
    "                # crop some of the images by 0-10% of their height/width\n",
    "                sometimes(iaa.Crop(percent=(0, 0.05))),\n",
    "\n",
    "                # Apply affine transformations to some of the images\n",
    "                # - scale to 80-120% of image height/width (each axis independently)\n",
    "                # - translate by -20 to +20 relative to height/width (per axis)\n",
    "                # - rotate by -45 to +45 degrees\n",
    "                # - shear by -16 to +16 degrees\n",
    "                # - order: use nearest neighbour or bilinear interpolation (fast)\n",
    "                # - mode: use any available mode to fill newly created pixels\n",
    "                #         see API or scikit-image for which modes are available\n",
    "                # - cval: if the mode is constant, then use a random brightness\n",
    "                #         for the newly created pixels (e.g. sometimes black,\n",
    "                #         sometimes white)\n",
    "                iaa.Affine(\n",
    "                    scale={\"x\": (1, 1.1), \"y\": (1, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
    "                    translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -10 to +10 percent (per axis)\n",
    "                    rotate=(-15, 15), # rotate by -15 to +15 degrees\n",
    "                    shear=(-8, 8), # shear by -8 to +8 degrees\n",
    "                    order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "                    #cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                    mode=['edge'] # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "                ),\n",
    "\n",
    "                #\n",
    "                # Execute 0 to 5 of the following (less important) augmenters per\n",
    "                # image. Don't execute all of them, as that would often be way too\n",
    "                # strong.\n",
    "                #\n",
    "                iaa.SomeOf((0, 5),\n",
    "                    [\n",
    "                        # Convert some images into their superpixel representation,\n",
    "                        # sample between 20 and 200 superpixels per image, but do\n",
    "                        # not replace all superpixels with their average, only\n",
    "                        # some of them (p_replace).\n",
    "                        sometimes(\n",
    "                            iaa.Superpixels(\n",
    "                                p_replace=(0, 0.1),\n",
    "                                n_segments=(50, 200)\n",
    "                            )\n",
    "                        ),\n",
    "\n",
    "                        # Blur each image with varying strength using\n",
    "                        # gaussian blur (sigma between 0 and 3.0),\n",
    "                        # average/uniform blur (kernel size between 2x2 and 7x7)\n",
    "                        # median blur (kernel size between 3x3 and 11x11).\n",
    "                        iaa.OneOf([\n",
    "                            iaa.GaussianBlur((0, 3.0)),\n",
    "                            iaa.AverageBlur(k=(2, 7)),\n",
    "                            iaa.MedianBlur(k=(3, 11)),\n",
    "                        ]),\n",
    "\n",
    "                        # Sharpen each image, overlay the result with the original\n",
    "                        # image using an alpha between 0 (no sharpening) and 1\n",
    "                        # (full sharpening effect).\n",
    "                        iaa.Sharpen(alpha=(0, 0.3), lightness=(0.75, 1.5)),\n",
    "\n",
    "                        # Same as sharpen, but for an embossing effect.\n",
    "                        iaa.Emboss(alpha=(0, 0.3), strength=(0, 2)),\n",
    "\n",
    "                        # Search in some images either for all edges or for\n",
    "                        # directed edges. These edges are then marked in a black\n",
    "                        # and white image and overlayed with the original image\n",
    "                        # using an alpha of 0 to 0.7.\n",
    "                        sometimes(iaa.OneOf([\n",
    "                            iaa.EdgeDetect(alpha=(0, 0.3)),\n",
    "                            iaa.DirectedEdgeDetect(\n",
    "                                alpha=(0, 0.3), direction=(0.0, 1.0)\n",
    "                            ),\n",
    "                        ])),\n",
    "\n",
    "                        # Add gaussian noise to some images.\n",
    "                        # In 50% of these cases, the noise is randomly sampled per\n",
    "                        # channel and pixel.\n",
    "                        # In the other 50% of all cases it is sampled once per\n",
    "                        # pixel (i.e. brightness change).\n",
    "                        iaa.AdditiveGaussianNoise(\n",
    "                            loc=0, scale=(0.0, 0.05*255), per_channel=0.5\n",
    "                        ),\n",
    "\n",
    "                        # Either drop randomly 1 to 10% of all pixels (i.e. set\n",
    "                        # them to black) or drop them on an image with 2-5% percent\n",
    "                        # of the original size, leading to large dropped\n",
    "                        # rectangles.\n",
    "                        iaa.OneOf([\n",
    "                            iaa.Dropout((0.01, 0.02), per_channel=0.5),\n",
    "                            #iaa.CoarseDropout(\n",
    "                            #    (0.03, 0.15), size_percent=(0.02, 0.05),\n",
    "                            #    per_channel=0.2\n",
    "                            #),\n",
    "                        ]),\n",
    "\n",
    "                        # Invert each image's chanell with 5% probability.\n",
    "                        # This sets each pixel value v to 255-v.\n",
    "                        #iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "\n",
    "                        # Add a value of -10 to 10 to each pixel.\n",
    "                        iaa.Add((-15, 15), per_channel=0.5),\n",
    "\n",
    "                        # Change brightness of images (50-150% of original value).\n",
    "                        iaa.Multiply((0.75, 1.25), per_channel=0.5),\n",
    "\n",
    "                        # Improve or worsen the contrast of images.\n",
    "                        iaa.ContrastNormalization((0.75, 1.75), per_channel=0.5),\n",
    "\n",
    "                        # Convert each image to grayscale and then overlay the\n",
    "                        # result with the original with random alpha. I.e. remove\n",
    "                        # colors with varying strengths.\n",
    "                        iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "\n",
    "                        # In some images move pixels locally around (with random\n",
    "                        # strengths).\n",
    "                        #sometimes(\n",
    "                        #    iaa.ElasticTransformation(alpha=(0.1, 0.2), sigma=0.25)\n",
    "                        #),\n",
    "\n",
    "                        # In some images distort local areas with varying strength.\n",
    "                        sometimes(iaa.PiecewiseAffine(scale=(0.005, 0.01)))\n",
    "                    ],\n",
    "                    # do all of the above augmentations in random order\n",
    "                    random_order=True\n",
    "                )\n",
    "            ],\n",
    "            # do all of the above augmentations in random order\n",
    "            random_order=True\n",
    "        )\n",
    "\n",
    "        def __call__(self, img):\n",
    "\n",
    "            img = np.array(img)\n",
    "            return self.aug.augment_image(img)\n",
    "\n",
    "    class ImageDataset(Dataset):\n",
    "\n",
    "        def __init__(self, data_frame, transform=None):\n",
    "\n",
    "            self.data_frame = data_frame\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "\n",
    "            return len(self.data_frame)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            #idx is index from dataset\n",
    "            #This is a mapping from your data_frame to the output of the mode\n",
    "            img_name = self.data_frame.loc[idx, 'ImageName']\n",
    "\n",
    "            expression = self.data_frame.loc[idx, 'Expression']\n",
    "            gender = self.data_frame.loc[idx, 'gender_preds']\n",
    "\n",
    "            # read image as ndarray, H*W*C\n",
    "            image = dlib.load_rgb_image(img_name)       \n",
    "            image = cv2.resize(image, (224,224)) # resize the image to 224x224 for the ResNet Model\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            # transform label to torch tensor\n",
    "            # This sets the order of the label\n",
    "            return (image, torch.from_numpy(np.asarray(expression, dtype=np.float32)), \n",
    "                    torch.from_numpy(np.asarray(gender, dtype=np.float32)))\n",
    "\n",
    "\n",
    "    transform_train_data = transforms.Compose([\n",
    "        ImgAugTransform(),\n",
    "        lambda x: PIL.Image.fromarray(x),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    transformed_train_dataset = ImageDataset(data_frame=train_frame,\n",
    "                                               transform=transform_train_data\n",
    "                                               )\n",
    "\n",
    "    train_dataloader = DataLoader(transformed_train_dataset, batch_size=64,\n",
    "                            shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "    transform_val_data = transforms.Compose(([transforms.ToPILImage(), \n",
    "                                          transforms.ToTensor(), \n",
    "                                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                              ]))\n",
    "\n",
    "    transformed_val_dataset = ImageDataset(data_frame=val_frame,\n",
    "                                               transform=transform_val_data\n",
    "                                               )\n",
    "\n",
    "    val_dataloader = DataLoader(transformed_val_dataset, batch_size=64,\n",
    "                            shuffle=False, num_workers=8)\n",
    "\n",
    "    transform_test_data = transforms.Compose(([transforms.ToPILImage(), \n",
    "                                          transforms.ToTensor(), \n",
    "                                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                              ]))\n",
    "\n",
    "    transformed_test_dataset = ImageDataset(data_frame=test_frame,\n",
    "                                               transform=transform_test_data\n",
    "                                               )\n",
    "\n",
    "    test_dataloader = DataLoader(transformed_test_dataset, batch_size=64,\n",
    "                            shuffle=False, num_workers=8)\n",
    "\n",
    "    # Training\n",
    "\n",
    "    torch.cuda.is_available()\n",
    "\n",
    "    dataloaders = {'train': train_dataloader, 'test': test_dataloader}\n",
    "    dataset_sizes = {'train': len(transformed_train_dataset), 'test': len(transformed_test_dataset)}\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # utils.py\n",
    "\n",
    "    import json\n",
    "    import pickle\n",
    "    from sklearn.metrics import average_precision_score\n",
    "\n",
    "    def save_pkl(pkl_data, save_path):\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(pkl_data, f)\n",
    "\n",
    "    def load_pkl(load_path):\n",
    "        with open(load_path, 'rb') as f:\n",
    "            pkl_data = pickle.load(f)\n",
    "        return pkl_data\n",
    "\n",
    "    def save_json(json_data, save_path):\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump(json_data, f)\n",
    "\n",
    "    def load_json(load_path):\n",
    "        with open(load_path, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "        return json_data\n",
    "\n",
    "    def save_state_dict(state_dict, save_path):\n",
    "        torch.save(state_dict, save_path)\n",
    "\n",
    "    def creat_folder(path):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "    def set_random_seed(seed_number):\n",
    "        torch.manual_seed(seed_number)\n",
    "        np.random.seed(seed_number)\n",
    "\n",
    "    def write_info(filename, info):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(info)\n",
    "\n",
    "    def compute_weighted_AP(target, predict_prob, class_weight_list):\n",
    "        per_class_AP = []\n",
    "        for i in range(target.shape[1] - 1):\n",
    "            class_weight = target[:, i]*class_weight_list[i] \\\n",
    "                           + (1-target[:, i])*np.ones(class_weight_list[i].shape)\n",
    "            per_class_AP.append(average_precision_score(target[:, i], predict_prob[:], \n",
    "                                    sample_weight=class_weight))\n",
    "\n",
    "        return per_class_AP\n",
    "\n",
    "    def compute_mAP(per_class_AP):\n",
    "        return np.mean([per_class_AP[idx] for idx in [0]])\n",
    "\n",
    "    def compute_class_weight(target):\n",
    "        domain_label = target[:, -1]\n",
    "        per_class_weight = []\n",
    "\n",
    "        for i in range(target.shape[1]-1):\n",
    "            class_label = target[:, i]\n",
    "            cp = class_label.sum() # class is positive\n",
    "            cn = target.shape[0] - cp # class is negative\n",
    "            cn_dn = ((class_label + domain_label)==0).sum() # class is negative, domain is negative\n",
    "            cn_dp = ((class_label - domain_label)==-1).sum()\n",
    "            cp_dn = ((class_label - domain_label)==1).sum()\n",
    "            cp_dp = ((class_label + domain_label)==2).sum()\n",
    "\n",
    "            per_class_weight.append(\n",
    "                (class_label*cp + (1-class_label)*cn) / \n",
    "                    (2*(\n",
    "                        (1-class_label)*(1-domain_label)*cn_dn\n",
    "                        + (1-class_label)*domain_label*cn_dp\n",
    "                        + class_label*(1-domain_label)*cp_dn\n",
    "                        + class_label*domain_label*cp_dp\n",
    "                       )\n",
    "                    )\n",
    "            )\n",
    "        return per_class_weight\n",
    "\n",
    "    # celeba_uniconf_adv.py\n",
    "    class ResNet50_base(nn.Module):   \n",
    "        \"\"\"ResNet50 but without the final fc layer\"\"\"\n",
    "\n",
    "        def __init__(self, pretrained, hidden_size=2048, dropout=0.5):\n",
    "            super().__init__()\n",
    "            self.resnet = torchvision.models.resnet50(pretrained=pretrained)                \n",
    "            self.resnet.fc = nn.Linear(2048, hidden_size)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(dropout)        \n",
    "\n",
    "        def require_all_grads(self):\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        def forward(self, x):\n",
    "            features = self.resnet(x)\n",
    "            features = self.dropout(self.relu(features))\n",
    "\n",
    "            return features\n",
    "\n",
    "    class CelebaUniConfAdv():\n",
    "        def __init__(self):\n",
    "            self.training_ratio = 3\n",
    "            self.alpha = 2\n",
    "            self.epoch = 0\n",
    "            self.best_dev_mAP = 0.\n",
    "            self.train_loader = train_dataloader    \n",
    "            self.dev_loader = val_dataloader        \n",
    "            self.test_loader = test_dataloader\n",
    "\n",
    "            self.dev_target = val_frame.iloc[:,[1,2]].to_numpy()\n",
    "            self.dev_class_weight = compute_class_weight(self.dev_target)\n",
    "            self.test_target = test_frame.iloc[:,[1,2]].to_numpy()\n",
    "            self.test_class_weight = compute_class_weight(self.test_target)\n",
    "\n",
    "\n",
    "            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "            self.base_network = ResNet50_base(pretrained=True).to(self.device)\n",
    "\n",
    "\n",
    "            num_female = len(train_frame[train_frame.gender_preds == 0])\n",
    "            num_male = len(train_frame[train_frame.gender_preds == 1])\n",
    "            weight_gender = torch.tensor([num_male/num_female, num_male/num_male]).to(self.device)\n",
    "\n",
    "            self.criterion = nn.CrossEntropyLoss(weight = weight_gender)\n",
    "            # Two fc layers on top of the base network, one for target classification,\n",
    "            # one for domain classification\n",
    "            self.class_network = nn.Linear(2048, 1).to(self.device)\n",
    "            self.domain_network = nn.Linear(2048, 2).to(self.device)\n",
    "\n",
    "\n",
    "\n",
    "            self.base_optimizer = torch.optim.Adam( \n",
    "                                      params=filter(lambda p: p.requires_grad, self.base_network.parameters()), \n",
    "                                      lr=1e-4)\n",
    "            self.class_optimizer = torch.optim.Adam( \n",
    "                                      params=filter(lambda p: p.requires_grad, self.class_network.parameters()), \n",
    "                                      lr=1e-4)\n",
    "            self.domain_optimizer = torch.optim.Adam( \n",
    "                                      params=filter(lambda p: p.requires_grad, self.domain_network.parameters()), \n",
    "                                      lr=1e-4)\n",
    "\n",
    "        def _criterion(self, output, expression):\n",
    "            return F.binary_cross_entropy_with_logits(torch.squeeze(output), expression.float())\n",
    "            #return self.criterion(torch.squeeze(output), expression.long())\n",
    "\n",
    "        def _domain_criterion(self, output, gender):\n",
    "\n",
    "            return self.criterion(torch.squeeze(output), gender.long())\n",
    "\n",
    "        def state_dict(self):\n",
    "            state_dict = {\n",
    "                'base_network': self.base_network.state_dict(),\n",
    "                'class_network': self.class_network.state_dict(),\n",
    "                'domain_network': self.domain_network.state_dict(),\n",
    "                'base_optimizer': self.base_optimizer.state_dict(),\n",
    "                'class_optimizer': self.class_optimizer.state_dict(),\n",
    "                'domain_optimizer': self.domain_optimizer.state_dict(),\n",
    "                'epoch': self.epoch\n",
    "            }\n",
    "            return state_dict\n",
    "\n",
    "        def load_state_dict(self, state_dict):\n",
    "            self.base_network.load_state_dict(state_dict['base_network'])\n",
    "            self.class_network.load_state_dict(state_dict['class_network'])\n",
    "            self.domain_network.load_state_dict(state_dict['domain_network'])\n",
    "\n",
    "        def inference(self, output):\n",
    "            predict_prob = torch.sigmoid(output)\n",
    "            return predict_prob.cpu().numpy()\n",
    "\n",
    "        def _train(self, loader):\n",
    "            \"\"\"Train the model for one epoch\"\"\"\n",
    "\n",
    "            self.base_network.train()\n",
    "            self.class_network.train()\n",
    "            self.domain_network.train()\n",
    "\n",
    "            train_class_loss = 0\n",
    "            train_domain_loss = 0\n",
    "            total = 0\n",
    "            class_correct = 0\n",
    "            domain_correct = 0\n",
    "            for i, (images, expression, gender) in enumerate(loader):\n",
    "                images, expression, gender = images.to(self.device), expression.to(self.device), gender.to(self.device)\n",
    "\n",
    "                self.base_optimizer.zero_grad()\n",
    "                self.class_optimizer.zero_grad()\n",
    "                self.domain_optimizer.zero_grad()\n",
    "\n",
    "                features = self.base_network(images)\n",
    "                class_outputs = torch.squeeze(self.class_network(features))\n",
    "                domain_outputs = self.domain_network(features)\n",
    "\n",
    "\n",
    "                class_loss = self._criterion(class_outputs, expression)\n",
    "                domain_loss = self._domain_criterion(domain_outputs, gender)\n",
    "\n",
    "                total += expression.size(0)\n",
    "\n",
    "                class_predicted = torch.where(torch.sigmoid(class_outputs) >= 0.5, torch.ones_like(class_outputs), torch.zeros_like(class_outputs)).long()\n",
    "                #_, class_predicted = class_outputs.max(1)\n",
    "                class_correct += class_predicted.eq(expression.long()).sum().item()\n",
    "                _, domain_predicted = domain_outputs.max(1)\n",
    "                domain_correct += domain_predicted.eq(gender.long()).sum().item()\n",
    "\n",
    "\n",
    "                if i == 0 and self.epoch <= 10 and self.epoch % 3 == 0:\n",
    "                    print()\n",
    "                    print(\"class outputs:\")\n",
    "                    print(class_outputs)\n",
    "                    print(\"class predicted\")\n",
    "                    print(class_predicted)\n",
    "                    print(\"class loss\")\n",
    "                    print(class_loss)\n",
    "                    print()\n",
    "                    print(\"domain outputs:\")\n",
    "                    print(domain_outputs)\n",
    "                    print(\"domain predicted\")\n",
    "                    print(domain_predicted)\n",
    "                    print(\"domain loss\")\n",
    "                    print(domain_loss)\n",
    "\n",
    "\n",
    "                # Update the main network\n",
    "                if self.epoch % self.training_ratio == 0:\n",
    "                    log_softmax = F.log_softmax(domain_outputs, dim=1)\n",
    "                    confusion_loss = -log_softmax.mean(dim=1).mean()\n",
    "                    loss = class_loss + self.alpha*confusion_loss\n",
    "                    loss.backward()\n",
    "                    self.class_optimizer.step()\n",
    "                    self.base_optimizer.step()\n",
    "                else:\n",
    "                    # Update the domain classifier\n",
    "                    domain_loss.backward()\n",
    "                    self.domain_optimizer.step()\n",
    "\n",
    "                train_class_loss += class_loss.item()\n",
    "                train_domain_loss += domain_loss.item()\n",
    "                #print('Train iteration', \n",
    "                #                {'class_loss': class_loss.item(),\n",
    "                #                 'domain_loss': domain_loss.item(),\n",
    "                #                 'domain_accuracy': 100.*correct/total},\n",
    "                #                len(loader)*self.epoch + i)\n",
    "\n",
    "                self.print_freq = 50\n",
    "\n",
    "                #if self.print_freq and (i % self.print_freq == 0):\n",
    "            print('Training epoch {}: [{}|{}], class loss:{}, class accuracy: {}, domain loss: {}, domain accuracy: {}'\n",
    "                          .format(self.epoch, i+1, len(loader), \n",
    "                                  class_loss.item(), 100.*class_correct/total, domain_loss.item(),\n",
    "                                  100.*domain_correct/total))\n",
    "\n",
    "            #self.log_result('Train epoch', \n",
    "            #                {'class_loss': train_class_loss/len(loader),\n",
    "            #                 'domain_loss': train_domain_loss/len(loader),\n",
    "            #                 'domain_accuracy': 100.*correct/total}, \n",
    "            #                self.epoch)\n",
    "            self.epoch += 1\n",
    "\n",
    "        def _test(self, loader):\n",
    "            \"\"\"Compute model output on test set\"\"\"\n",
    "\n",
    "            self.base_network.eval()\n",
    "            self.class_network.eval()\n",
    "            self.domain_network.eval()\n",
    "\n",
    "            test_class_loss = 0\n",
    "            test_domain_loss = 0\n",
    "            total = 0\n",
    "            class_correct = 0\n",
    "            domain_correct = 0\n",
    "            feature_list = []\n",
    "            class_output_list = []\n",
    "            domain_output_list = []\n",
    "            with torch.no_grad():\n",
    "                for i, (images, expression, gender) in enumerate(loader):\n",
    "                    images, expression, gender = images.to(self.device), expression.to(self.device), gender.to(self.device)\n",
    "                    features = self.base_network(images)\n",
    "                    class_outputs = torch.squeeze(self.class_network(features))\n",
    "                    domain_outputs = self.domain_network(features)\n",
    "\n",
    "                    class_loss = self._criterion(class_outputs, expression)\n",
    "                    domain_loss = self._domain_criterion(domain_outputs, gender)\n",
    "                    test_class_loss += class_loss.item()\n",
    "                    test_domain_loss += domain_loss.item()\n",
    "\n",
    "                    total += expression.size(0)\n",
    "\n",
    "                    class_predicted = torch.where(torch.sigmoid(class_outputs) >= 0.5, torch.ones_like(class_outputs), torch.zeros_like(class_outputs)).long()\n",
    "                    class_correct += class_predicted.eq(expression.long()).sum().item()\n",
    "\n",
    "                    _, domain_predicted = domain_outputs.max(1)\n",
    "                    domain_correct += domain_predicted.eq(gender.long()).sum().item()\n",
    "\n",
    "                    class_output_list.append(class_outputs)\n",
    "                    domain_output_list.append(domain_outputs)\n",
    "                    feature_list.append(features)\n",
    "\n",
    "                #print('Testing epoch, class loss:{}, class accuracy: {}, domain loss: {}, domain accuracy: {}'\n",
    "                #          .format(test_class_loss, 100.*class_correct/total, test_domain_loss, \n",
    "                #                  100.*domain_correct/total))\n",
    "                return test_class_loss, test_domain_loss, torch.cat(class_output_list), 100.*class_correct/total, \\\n",
    "                       torch.cat(domain_output_list), torch.cat(feature_list), 100.*domain_correct/total\n",
    "\n",
    "        def public_test(self, images):\n",
    "            \"\"\"Compute model output on test set\"\"\"\n",
    "\n",
    "            self.base_network.eval()\n",
    "            self.class_network.eval()\n",
    "            self.domain_network.eval()\n",
    "\n",
    "\n",
    "            features = self.base_network(images)\n",
    "            class_outputs = torch.squeeze(self.class_network(features))\n",
    "            domain_outputs = self.domain_network(features)\n",
    "\n",
    "            return torch.sigmoid(class_outputs), domain_outputs\n",
    "\n",
    "        def train(self):\n",
    "            \"\"\"Train the model for one epoch, evaluate on validation set and \n",
    "            save the best model\n",
    "            \"\"\"\n",
    "\n",
    "            start_time = datetime.now()\n",
    "            learning_rates1 = [1e-4, 1e-5, 1e-6] # class_optimizer\n",
    "            learning_rates2 = [1e-3, 1e-4, 1e-5] # domain_optimizer\n",
    "            epochs = [3, 6, 12]\n",
    "\n",
    "            for learning_rate1, learning_rate2, epoch in zip(learning_rates1, learning_rates2, epochs):\n",
    "                print()\n",
    "                print('learning rate:', learning_rate1)\n",
    "                print('epoch number:', epoch)\n",
    "                self.base_optimizer = torch.optim.Adam( \n",
    "                                      params=filter(lambda p: p.requires_grad, self.base_network.parameters()), \n",
    "                                      lr=learning_rate1)\n",
    "                self.class_optimizer = torch.optim.Adam( \n",
    "                                          params=filter(lambda p: p.requires_grad, self.class_network.parameters()), \n",
    "                                          lr=learning_rate1, weight_decay=1e-5)\n",
    "                self.domain_optimizer = torch.optim.Adam( \n",
    "                                          params=filter(lambda p: p.requires_grad, self.domain_network.parameters()), \n",
    "                                          lr=learning_rate2, weight_decay=1e-5)\n",
    "                for i in range(epoch):\n",
    "                    print()\n",
    "                    self._train(self.train_loader)\n",
    "\n",
    "                    dev_class_loss, dev_domain_loss, dev_class_output,dev_class_accuarcy, _,_, dev_domain_accuarcy = self._test(self.dev_loader)\n",
    "                    dev_predict_prob = self.inference(dev_class_output)\n",
    "                    dev_per_class_AP = compute_weighted_AP(self.dev_target, dev_predict_prob, \n",
    "                                                                 self.dev_class_weight)\n",
    "                    dev_mAP = compute_mAP(dev_per_class_AP)\n",
    "\n",
    "\n",
    "                    print('Testing epoch, class loss:{},  class accuracy: {}, mAP: {}, domain loss: {}, domain accuracy: {}'\n",
    "                              .format(dev_class_loss/len(self.dev_loader), dev_class_accuarcy, dev_mAP,  \n",
    "                                      dev_domain_loss/len(self.dev_loader), dev_domain_accuarcy))\n",
    "\n",
    "                    #self.log_result('Dev epoch', \n",
    "                    #                {'class_loss': dev_class_loss/len(self.dev_loader), \n",
    "                    #                 'domain_loss': dev_domain_loss/len(self.dev_loader),\n",
    "                    #                 'mAP': dev_mAP,\n",
    "                    #                 'domain_accuracy': dev_domain_accuarcy},\n",
    "                    #                self.epoch)\n",
    "                    #if (self.epoch) > 1 and (dev_mAP > self.best_dev_mAP):\n",
    "                    #    self.best_dev_mAP = dev_mAP\n",
    "                    #\n",
    "                    #    best_model_wts = copy.deepcopy(self.state_dict())\n",
    "                    #    \n",
    "                    #    \n",
    "                    #    save_state_dict(self.state_dict(), os.path.join(\"./test/\", 'best.pth'))\n",
    "                    #if\n",
    "                    #    print('best mAP, loss update:', dev_class_accuarcy, self.best_dev_mAP)\n",
    "                    #else:\n",
    "                    #    print('best mAP, loss not update, still:', dev_class_accuarcy, self.best_dev_mAP)\n",
    "\n",
    "                #self.load_state_dict(best_model_wts)\n",
    "                save_state_dict(self.state_dict(), os.path.join(\"./\", 'uniconf_' + str(k) + '.pth'))\n",
    "            duration = datetime.now() - start_time\n",
    "            print('Finish training epoch {}, dev class loss: {}, dev doamin loss: {}, dev mAP: {},'\\\n",
    "                  'domain_accuracy: {}, time used: {}'\n",
    "                  .format(self.epoch, dev_class_loss/len(self.dev_loader), \n",
    "                          dev_domain_loss/len(self.dev_loader), dev_mAP, dev_domain_accuarcy,\n",
    "                          duration))\n",
    "\n",
    "        def test(self):\n",
    "            # Test and save the result\n",
    "            state_dict = torch.load(os.path.join(\"./\", 'uniconf_' + str(k) + '.pth'))\n",
    "            self.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "\n",
    "            test_class_loss, test_domain_loss, test_class_output, test_class_accuarcy, test_domain_output, \\\n",
    "                test_feature, test_domain_accuracy = self._test(self.test_loader)\n",
    "            test_predict_prob = self.inference(test_class_output)\n",
    "            test_per_class_AP = compute_weighted_AP(self.test_target, test_predict_prob, \n",
    "                                                         self.test_class_weight)\n",
    "            test_mAP = compute_mAP(test_per_class_AP)\n",
    "            print('per_class_AP', test_per_class_AP)\n",
    "            print('mAP', test_mAP)\n",
    "            print('domain_accuracy', test_domain_accuracy)\n",
    "            return test_class_output.cpu().numpy(), test_domain_output.cpu().numpy(), test_feature.cpu().numpy()\n",
    "\n",
    "    model = CelebaUniConfAdv()\n",
    "    model.train()\n",
    "\n",
    "\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "\n",
    "    # predict on test\n",
    "\n",
    "\n",
    "    #model = CelebaUniConfAdv()\n",
    "    #model.load_state_dict(torch.load('./test/best_uniconf.pth'))\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    face_names = []\n",
    "    scores = []\n",
    "    preds = []\n",
    "\n",
    "    true_labels = []\n",
    "\n",
    "    gender_preds = []\n",
    "    true_gender_labels = []\n",
    "\n",
    "    for index, row in test_frame.iterrows():\n",
    "\n",
    "        if index % 200 == 0:\n",
    "            print(index)\n",
    "\n",
    "        image_name = row['ImageName']\n",
    "\n",
    "        image = dlib.load_rgb_image(image_name)\n",
    "        image = trans(image)\n",
    "        image = image.view(1, 3, 224, 224)\n",
    "        image = image.to(device)\n",
    "\n",
    "        outputs, gender_outputs = model.public_test(image)\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = np.squeeze(outputs)\n",
    "\n",
    "        score = outputs * 1\n",
    "        #score = np.exp(outputs) / np.sum(np.exp(outputs))\n",
    "        pred = (score>=0.5)*1\n",
    "        #pred = np.argmax(score)\n",
    "\n",
    "        gender_outputs = gender_outputs.cpu().detach().numpy()\n",
    "        gender_outputs = np.squeeze(gender_outputs)\n",
    "\n",
    "        gender_score = np.exp(gender_outputs) / np.sum(np.exp(gender_outputs))\n",
    "        gender_pred = np.argmax(gender_score)\n",
    "\n",
    "        face_names.append(image_name)\n",
    "        scores.append(score)\n",
    "        preds.append(pred)\n",
    "        gender_preds.append(gender_pred)\n",
    "\n",
    "        true_labels.append(row['Expression'])\n",
    "        true_gender_labels.append(row['gender_preds'])\n",
    "\n",
    "    test_result = pd.DataFrame(list(zip(face_names, scores, preds, true_labels, gender_preds, true_gender_labels)), \n",
    "                 columns = ['ImageName', 'ExpressionScore', 'Prediction', 'Expression', 'GenderPrediction', 'Gender'])\n",
    "    test_result.head(10)\n",
    "\n",
    "    # Accuracy\n",
    "    test_result['CorrectOrNot'] = (test_result.Prediction == test_result.Expression)\n",
    "    test_result['CorrectOrNot_gender'] = (test_result.GenderPrediction == test_result.Gender)\n",
    "\n",
    "\n",
    "    dict_row = {}\n",
    "    dict_row['model_random_state'] = k\n",
    "    dict_row['test_accuracy'] = test_result.CorrectOrNot.mean()\n",
    "    dict_row['test_gender_accuracy'] = test_result.CorrectOrNot_gender.mean()\n",
    "    dict_row['test_male_true_proportion'] = (test_result[test_result.Gender == 1].Expression==1).mean()\n",
    "    dict_row['test_female_true_proportion'] = (test_result[test_result.Gender == 0].Expression==1).mean()\n",
    "    dict_row['test_male_predicted_proportion'] = (test_result[test_result.Gender == 1].Prediction==1).mean()\n",
    "    dict_row['test_female_predicted_proportion'] = (test_result[test_result.Gender == 0].Prediction==1).mean()\n",
    "    dict_row['test_male_average_score'] = test_result[test_result.Gender == 1].ExpressionScore.mean()\n",
    "    dict_row['test_female_average_score'] = test_result[test_result.Gender == 0].ExpressionScore.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Apply on Chicago Face\n",
    "\n",
    "    chicago_df = pd.read_csv('ChicagoFace_selected_evaluation_set2.csv').iloc[:,0:4]\n",
    "    chicago_df.head()\n",
    "\n",
    "    def expression_string_to_num(s):\n",
    "        if s == \"Happy\":\n",
    "            return 3\n",
    "        elif s == \"Angry\":\n",
    "            return 0\n",
    "        elif s == \"Fear\":\n",
    "            return 2\n",
    "        else:\n",
    "            return 6\n",
    "\n",
    "    chicago_df[\"Expression_num\"] = chicago_df.Expression.apply(expression_string_to_num)\n",
    "\n",
    "\n",
    "    chicago_df[\"happy\"] = chicago_df.Expression_num.apply(lambda x: 1 if x == 3 else 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    face_names = []\n",
    "    scores = []\n",
    "    preds = []\n",
    "\n",
    "    true_labels = []\n",
    "\n",
    "    gender_preds = []\n",
    "\n",
    "    for index, row in chicago_df.iterrows():\n",
    "\n",
    "        #if index >= 100: break\n",
    "\n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "\n",
    "        image_name = row['ImageName']\n",
    "\n",
    "\n",
    "        image = dlib.load_rgb_image(image_name)\n",
    "        image = trans(image)\n",
    "        image = image.view(1, 3, 224, 224)\n",
    "        image = image.to(device)\n",
    "\n",
    "        outputs, gender_outputs = model.public_test(image)\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = np.squeeze(outputs)\n",
    "\n",
    "        score = outputs * 1\n",
    "        #score = np.exp(outputs) / np.sum(np.exp(outputs))\n",
    "        pred = (score>=0.5)*1\n",
    "        #pred = np.argmax(score)\n",
    "\n",
    "        gender_outputs = gender_outputs.cpu().detach().numpy()\n",
    "        gender_outputs = np.squeeze(gender_outputs)\n",
    "\n",
    "        gender_score = np.exp(gender_outputs) / np.sum(np.exp(gender_outputs))\n",
    "        gender_pred = np.argmax(gender_score)\n",
    "\n",
    "        face_names.append(image_name)\n",
    "        scores.append(score)\n",
    "        preds.append(pred)\n",
    "        gender_preds.append(gender_pred)\n",
    "\n",
    "        true_labels.append(row['happy'])\n",
    "\n",
    "    chicago_result = pd.DataFrame([face_names, preds, scores, gender_preds]).T\n",
    "\n",
    "    chicago_result.columns = ['ImageName', 'expression_preds', 'expression_scores', 'gender_preds_model']\n",
    "\n",
    "\n",
    "    chicago_result[\"happiness_score\"] = chicago_result.expression_scores.apply(lambda x: x)\n",
    "\n",
    "\n",
    "    num_happy = (chicago_df.happy == 1).sum()\n",
    "    threshold = chicago_result.sort_values(by = ['happiness_score'], ascending = False).reset_index(drop = True).iloc[num_happy]['happiness_score']\n",
    "\n",
    "    chicago_result['expression_preds_relabeled'] = chicago_result.happiness_score.apply(lambda x : 1 if x > threshold else 0)\n",
    "\n",
    "\n",
    "    chicago_df_merged = pd.merge(chicago_df, chicago_result, on = ['ImageName'], how = 'left')\n",
    "\n",
    "    chicago_df_merged[\"true_gender\"] = chicago_df_merged.Gender.apply(lambda x: 1 if x == \"M\" else 0)\n",
    "\n",
    "\n",
    "    chicago_df_merged['CorrectOrNot'] = (chicago_df_merged.expression_preds_relabeled == chicago_df_merged.happy)\n",
    "    dict_row['selected_2_chicago_accuracy'] = chicago_df_merged.CorrectOrNot.mean() \n",
    "\n",
    "    dict_row['selected_2_chicago_gender_accuracy'] = (chicago_df_merged.gender_preds_model == chicago_df_merged.true_gender).mean()\n",
    "\n",
    "    chicago_male_frame = chicago_df_merged.loc[chicago_df_merged['Gender'] == 'M']\n",
    "    chicago_female_frame = chicago_df_merged.loc[chicago_df_merged['Gender'] == 'F']\n",
    "\n",
    "    # Accuracy between males and females\n",
    "    dict_row['selected_2_chicago_accuracy_male'] = (chicago_male_frame.expression_preds_relabeled == chicago_male_frame.happy).mean()\n",
    "    dict_row['selected_2_chicago_accuracy_female'] = (chicago_female_frame.expression_preds_relabeled == chicago_female_frame.happy).mean()\n",
    "\n",
    "    # True proportion\n",
    "    dict_row['selected_2_chicago_true_proportion'] = chicago_male_frame.happy.mean()\n",
    "\n",
    "    # Prediction proportion\n",
    "    dict_row['selected_2_chicago_male_predicted_proportion'] = chicago_male_frame.expression_preds_relabeled.mean()\n",
    "    dict_row['selected_2_chicago_female_predicted_proportion'] = chicago_female_frame.expression_preds_relabeled.mean()\n",
    "    dict_row['selected_2_chicago_bias'] = chicago_female_frame.expression_preds_relabeled.mean() - chicago_male_frame.expression_preds_relabeled.mean()\n",
    "\n",
    "    # Prediction proportion\n",
    "    dict_row['selected_2_chicago_male_predicted_proportion_raw'] = chicago_male_frame.expression_preds.mean()\n",
    "    dict_row['selected_2_chicago_female_predicted_proportion_raw'] = chicago_female_frame.expression_preds.mean()\n",
    "    dict_row['selected_2_chicago_bias_raw'] = chicago_female_frame.expression_preds.mean() - chicago_male_frame.expression_preds.mean()\n",
    "\n",
    "    # Average Happiness Score\n",
    "    dict_row['selected_2_chicago_male_score'] = chicago_male_frame.happiness_score.mean()\n",
    "    dict_row['selected_2_chicago_female_score'] = chicago_female_frame.happiness_score.mean()\n",
    "\n",
    "    # Average Happiness Score among neutral faces\n",
    "    dict_row['selected_2_chicago_male_score_neutral_faces'] = chicago_male_frame[chicago_male_frame.Expression_num == 6].happiness_score.mean()\n",
    "    dict_row['selected_2_chicago_female_score_neutral_faces'] = chicago_female_frame[chicago_female_frame.Expression_num == 6].happiness_score.mean()\n",
    "\n",
    "\n",
    "    result_rows_list.append(dict_row)\n",
    "    results_df = pd.DataFrame(result_rows_list) \n",
    "    print(results_df)\n",
    "    results_df.to_csv('model_evaluation_result.csv', index = False)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
